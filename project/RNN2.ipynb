{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.mp.model import Model  #导出库，只用这一个就够了\n",
    "import matplotlib.pyplot as plt#选取了用户47的365天的数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cplex\n",
    "from cplex.exceptions import CplexError\n",
    "import time\n",
    "import math\n",
    "import xlrd\n",
    "import torch\n",
    "from torch import nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.488, 5.16 , 4.754, 1.53 , 0.176, 0.308, 0.19 , 0.194, 0.174,\n",
       "       0.23 , 0.414, 0.88 , 1.802, 1.098, 0.394, 0.804, 0.246, 0.732,\n",
       "       1.548, 3.568, 3.074, 0.738, 0.56 , 0.392, 0.33 , 0.502, 0.368,\n",
       "       0.39 , 0.382, 0.348, 0.404, 0.33 , 0.326, 0.298, 0.406, 0.706,\n",
       "       0.368, 0.424, 0.628, 0.594, 0.81 , 2.252, 2.708, 0.478, 1.596,\n",
       "       1.588, 0.228, 0.666], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read file, for example\n",
    "file_path = 'C:/Users/chenxihui/Desktop/code/project/2012.csv'\n",
    "file = open(file_path)\n",
    "data = []\n",
    "for i in file.readlines():\n",
    "    data.append(i)\n",
    "file.close()\n",
    "\n",
    "new_data = []\n",
    "for row in data:\n",
    "    tmp = row.strip('\\n')  #去掉每行最后的回车符\n",
    "    tmp = tmp.split(',')   #根据','来分割字符串，使之成为含有一个个数据的列表\n",
    "    new_data.append(tmp)   #new_data的每一行数据就是一个列表\n",
    "select_data = []\n",
    "\n",
    "length=len(new_data)\n",
    "for i in range(length):\n",
    "    if(new_data[i][0]=='75'):#PVsize为8kwp\n",
    "        select_data.append(new_data[i][3:])#[3:]\n",
    "\n",
    "GC=[]\n",
    "CL=[]\n",
    "GG=[]\n",
    "Battery=[]\n",
    "Length_select_data = len(select_data)\n",
    "for i in range(Length_select_data):\n",
    "    if(select_data[i][0]=='GC'):\n",
    "        GC.append(select_data[i][2:])\n",
    "    elif(select_data[i][0]=='CL'):\n",
    "        CL.append(select_data[i][2:])\n",
    "    else:\n",
    "        GG.append(select_data[i][2:])\n",
    "        \n",
    "Total_Load=[]\n",
    "temp=[]\n",
    "a=0.0\n",
    "for i in range(Length_select_data):\n",
    "    if(select_data[i][0]=='GC' and select_data[i+1][0]=='CL'):\n",
    "        for j in range(len(select_data[i][2:])):\n",
    "            a=pd.to_numeric(select_data[i][j+2])+pd.to_numeric(select_data[i+1][j+2])\n",
    "            temp.append(a)\n",
    "        Total_Load.append(temp)\n",
    "    elif(select_data[i][0]=='GC' and select_data[i+1][0]!='CL'):\n",
    "        Total_Load.append(select_data[i][2:])\n",
    "    temp=[]\n",
    "    \n",
    "GC_temp=np.array(GC)\n",
    "GC_array=[]\n",
    "GC_array = GC_temp.astype(np.float)\n",
    "\n",
    "GG_temp=np.array(GG)\n",
    "GG_array=[]\n",
    "GG_array = GG_temp.astype(np.float)*2\n",
    "\n",
    "Total_Load_temp=np.array(Total_Load)\n",
    "Total_Load_array=[]\n",
    "Total_Load_array = Total_Load_temp.astype(np.float32)*2#功率\n",
    "Total_Load_array[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_bar=np.max(Total_Load_array)\n",
    "T_flat=0.235018\n",
    "T_fit=0.09\n",
    "T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl#之前将MILP得到的数据保存为xlsx文件，此为读取\n",
    "def read_data(road):\n",
    "    workbook=openpyxl.load_workbook(\"C:/Users/chenxihui/Desktop/code/project/processed_data/\"+road+\".xlsx\")\n",
    "    shenames=workbook.sheetnames\n",
    "    worksheet=workbook.worksheets[0]\n",
    "    name=worksheet.title \n",
    "    rows=worksheet.max_row\n",
    "    columns=worksheet.max_column\n",
    "    data_read=[[] for i in range(rows)]\n",
    "    i=0\n",
    "    for row in worksheet.rows:\n",
    "        for cell in row:\n",
    "            data_read[i].append(cell.value)\n",
    "        i=i+1\n",
    "    data_temp=np.array(data_read)\n",
    "    data_array=[]\n",
    "    data_array=data_temp.astype(np.float)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_y=read_data(\"soc\")#从第1天开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此版本为362天的样本数据点集合,从第一天开始算，但是第一天里都是空集合\n",
    "T_tou_temp=[]\n",
    "for i in range(3):\n",
    "    T_tou_temp.extend(T_tou)\n",
    "days=365    \n",
    "data_365=[[[] for _ in range(48)] for _ in range(days)]\n",
    "for d in range(days):\n",
    "    for i in range(48):\n",
    "        data_temp=[]\n",
    "        GG_temp=[]\n",
    "        soc_temp=[]#前48个SOC（包含当前时刻）\n",
    "    #print(len(soc_temp))\n",
    "        #data_temp.extend(soc_temp)\n",
    "        #print(\"data_temp：\",data_temp)\n",
    "        #print(\"#######################################\")\n",
    "        ToU_temp=[]\n",
    "        load_temp=[]\n",
    "        if(d<363 and d>0):\n",
    "            if(i==0):\n",
    "                soc_temp=np.hstack((soc_y[d-1][i+1:],soc_y[d][0:i+1]))\n",
    "                ToU_temp=np.hstack((T_tou[i:],T_tou))\n",
    "                #print(\"ToU_temp:\",ToU_temp)\n",
    "                load_temp=np.hstack((Total_Load_array[d][i:],Total_Load_array[d+1]))\n",
    "                GG_temp=np.hstack((GG[d][i:],GG[d+1]))\n",
    "            elif(i==47):\n",
    "                soc_temp=soc_y[d]\n",
    "                ToU_temp=np.hstack((T_tou,T_tou))\n",
    "                #print(\"ToU_temp:\",ToU_temp)\n",
    "                load_temp=np.hstack((Total_Load_array[d],Total_Load_array[d+1]))\n",
    "                GG_temp=np.hstack((GG[d],GG[d+1]))\n",
    "            else:\n",
    "                soc_temp=np.hstack((soc_y[d-1][i+1:],soc_y[d][0:i+1]))\n",
    "                ToU_temp=np.hstack((T_tou[i:],T_tou,T_tou[:i]))\n",
    "                GG_temp=np.hstack((GG[d][i:],GG[d+1],GG[d+2][:i]))\n",
    "                load_temp=np.hstack((Total_Load_array[d][i:],Total_Load_array[d+1],Total_Load_array[d+2][:i]))\n",
    "        #data_temp=np.hstack((data_temp,soc_temp))#用np.hstack\n",
    "        data_temp=soc_temp\n",
    "        #print(data_temp)\n",
    "        data_temp=np.hstack((data_temp,ToU_temp))\n",
    "        #print(data_temp)\n",
    "        #print(\"#######################################\")\n",
    "        data_temp=np.hstack((data_temp,list(map(float, GG_temp))))\n",
    "        #print(data_temp)\n",
    "        #print(\"#######################################\")\n",
    "        data_temp=np.hstack((data_temp,load_temp))\n",
    "        #print(len(data_temp[0][0]))\n",
    "    #print(len(data_temp))\n",
    "        data_365[d][i]=data_temp\n",
    "        #print(data_365[d][i])\n",
    "        #print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 7, 48)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soc_label=[[]for i in range(301)]\n",
    "for i in range(301):\n",
    "    for j in np.arange(1,48):\n",
    "        soc_label[i].append(soc_y[i+1][j])\n",
    "    soc_label[i].append(soc_y[i+2][0])\n",
    "soc_batch=np.split(soc_y[2:303],43,axis=0)\n",
    "#np.array(soc_batch).shape  (43, 7, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 48, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(soc_batch).transpose((0,2,1)).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 48, 7, 336)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array(data_365[1:302]).transpose((1,0,2))#[48, 301, 336]，\n",
    "#第二天第一个时刻作为第一个输入样本\n",
    "#np.array(soc_label).shape (301, 48)\n",
    "data_batch=np.split(a,43,axis=1)\n",
    "np.array(data_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 7, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array(soc_batch).transpose((0,2,1))[0][:,:,np.newaxis]).float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fc9dadafd795>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mbatch_nums\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m301\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_365\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m302\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#[48, 301, 336]，\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#第二天第一个时刻作为第一个输入样本\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#np.array(soc_label).shape (301, 48)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# 超参设置7*42为294\n",
    "TIME_STEP = 48  # RNN时间步长\n",
    "INPUT_SIZE = 336  # RNN输入尺寸\n",
    "INIT_LR = 10 # 初始学习率\n",
    "N_EPOCHS = 100  # 训练回数\n",
    "Batch_size=7\n",
    "batch_nums=43\n",
    "\n",
    "a=np.array(data_365[1:302]).transpose((1,0,2))#[48, 301, 336]，\n",
    "#第二天第一个时刻作为第一个输入样本\n",
    "#np.array(soc_label).shape (301, 48)\n",
    "data_batch=np.split(a,43,axis=1)\n",
    "#soc_batch=np.split(soc_y[2:303],43,axis=0)\n",
    "#soc_batch=soc_y\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=20,  # RNN隐藏神经元个数20\n",
    "            num_layers=1,  # RNN隐藏层个数\n",
    "        )\n",
    "        self.out = nn.Linear(20, 1).to(device)#全连接层，经过RNN网络后输出\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        # x (time_step, batch_size, input_size)\n",
    "        # h (n_layers, batch, hidden_size)\n",
    "        # out (time_step, batch_size, hidden_size)\n",
    "        out, h = self.rnn(x, h)\n",
    "        #print(\"out:\",out)\n",
    "        #print(\"h:\",h)\n",
    "        prediction = self.out(out)\n",
    "        #print(\"prediction:\",prediction)\n",
    "        return prediction, h\n",
    "\n",
    "\n",
    "rnn = RNN()\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=INIT_LR)\n",
    "loss_func = nn.MSELoss()\n",
    "#loss_func = torch.nn.CrossEntropyLoss()\n",
    "h_state = None  # 初始化隐藏层\n",
    "train_loss=[]\n",
    "plt.figure()\n",
    "plt.ion()\n",
    "steps=[i for i in range(48*7)]\n",
    "loss_min=20\n",
    "for step in range(N_EPOCHS):\n",
    "    error=0.0\n",
    "    in_start = time.time()\n",
    "    for batch_num in range(batch_nums):#此处分成了43个batch \n",
    "            #x = torch.from_numpy(np.array(a[batch_num])).float()  # 尺寸大小为(time_step, batch, input_size)\n",
    "            x=torch.from_numpy(np.array(data_batch[batch_num])).float().to(device)\n",
    "        #print(x.shape)\n",
    "            #y = torch.from_numpy(np.array(soc_batch[batch_num]).transpose((1,0))[:,:,np.newaxis]).float()\n",
    "            y=torch.from_numpy(np.array(soc_batch).transpose((0,2,1))[batch_num][:,:,np.newaxis]).float().to(device)\n",
    "            #y = torch.from_numpy(np.array(soc_y[batch_num+2])[:,np.newaxis,np.newaxis]).float().to(device)#48*1*1\n",
    "        #print(\"label:\",y)\n",
    "\n",
    "            prediction, h_state = rnn(x, h_state)  # RNN输出（预测结果，隐藏状态）\n",
    "            h_state = h_state.detach()  # 这一行很重要，将每一次输出的中间状态传递下去(不带梯度)\n",
    "            loss = loss_func(prediction, y)\n",
    "            error += loss\n",
    "            #print(\"epoch:\",step,\"batch_num:\",batch_num,\"loss:\",loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if(loss_min>loss):#返回最小的loss时的\n",
    "                loss_min=loss\n",
    "                minloss_batch=batch_num\n",
    "            #torch.save(rnn.state_dict(), 'C:/Users/chenxihui/Desktop/code/project/rnn.pt')\n",
    "            if(loss<5):\n",
    "                plt.cla()\n",
    "                plt.plot(steps, np.array(soc_batch[batch_num]).flatten(), 'r-')\n",
    "                plt.plot(steps, prediction.data.numpy().flatten(), 'b-')\n",
    "                plt.draw()\n",
    "                plt.pause(0.1)\n",
    "    in_time = time.time() - in_start\n",
    "    error /= batch_nums\n",
    "    train_loss.append(error)\n",
    "    print(\"Epoch: \" + str(step) + \", Loss = \" + str(error))\n",
    "print(\"Finished. Time = \" + str(time.time() - in_start))\n",
    "print(\"save model...\")\n",
    "if not os.path.exists(\"./model/\"):\n",
    "    os.makedirs(\"./model/\")\n",
    "filepath = \"./model/rnn2.model\"\n",
    "torch.save({\"model_state_dict\" : rnn.state_dict(),\n",
    "            \"optimizer_state_dict\" : optimizer.state_dict()},\n",
    "            filepath)   \n",
    "print(\"Model has been saved.\")\n",
    "print(\"h:\",h_state)\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "load model...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-aac1f3408d1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtest_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoc_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m302\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#print(predict)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Testing...\")\n",
    "print(\"load model...\")\n",
    "filepath = \"./model/rnn2.model\"\n",
    "checkpoint = torch.load(filepath)\n",
    "rnn.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "rnn.eval()\n",
    "\n",
    "test=np.array(data_365[302:342]).transpose((1,0,2))\n",
    "test_loss=[]   \n",
    "#hidden = rnn.init_hidden(1)\n",
    "plt.figure()\n",
    "plt.ion()\n",
    "steps=[i for i in range(48*1)]\n",
    "testloss_min=20\n",
    "for step in range(40):\n",
    "    test_x=torch.from_numpy(np.array(test[:,step,np.newaxis])).float().to(device)\n",
    "    test_y = torch.from_numpy(np.array(soc_label[step+302])[:,np.newaxis,np.newaxis]).float().to(device)\n",
    "    predict, h_state = rnn(test_x,h_state)\n",
    "    #print(predict)    \n",
    "    loss_test = loss_func(predict, test_y)\n",
    "    test_loss.append(loss_test)\n",
    "    if(testloss_min>loss_test):#返回最小的loss时的\n",
    "        testloss_min=loss_test\n",
    "        mintestloss_batch=step\n",
    "    print(\"loss:\",loss_test)\n",
    "    if(loss<15):\n",
    "        plt.cla()\n",
    "        plt.plot(steps, np.array(soc_label[step]).flatten(), 'r-')\n",
    "        plt.plot(steps, predict.data.numpy().flatten(), 'b-')\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "print(\"Test has been done!\")\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chen",
   "language": "python",
   "name": "chen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
