{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.mp.model import Model  #导出库，只用这一个就够了\n",
    "import matplotlib.pyplot as plt#选取了用户47的365天的数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cplex\n",
    "from cplex.exceptions import CplexError\n",
    "import time\n",
    "import math\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "import xlrd\n",
    "import torch\n",
    "from torch import nn\n",
    "#from matplotlib.animation import FuncAnimation\n",
    "#import matplotlib.animation as animation\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from random import uniform\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取指定用户的数据：返回GG_array,Total_Load_array,pv_size，此处乘以2，即为功率值\n",
    "def Read_year(year,user):\n",
    "    #read file, for example\n",
    "    file_path = 'C:/Users/chenxihui/Desktop/code/project/'+str(year)+'.csv'\n",
    "    file = open(file_path)\n",
    "    data = []\n",
    "    for i in file.readlines():\n",
    "        data.append(i)\n",
    "    file.close()\n",
    "    new_data = []\n",
    "\n",
    "    for row in data:\n",
    "        tmp = row.strip('\\n')  #去掉每行最后的回车符\n",
    "        tmp = tmp.split(',')   #根据','来分割字符串，使之成为含有一个个数据的列表\n",
    "        new_data.append(tmp)   #new_data的每一行数据就是一个列表\n",
    "    select_data = []\n",
    "    #position=[1,3,6,12,14,15,16,18,19,22,23,26,28,31,32,34,38,41,42,43,45,46,47]\n",
    "    #这是在cluster里分类产生的结果，是人数最多的类，以此为对象\n",
    "    users=['2','13','14','20','33','35','38','39','56','69','73','74','75'\n",
    "          ,'82','87','88','101','104','106','109','110','119','124','130'\n",
    "          ,'137','141','144','152','153','157','161','169','176','184','188'\n",
    "          ,'189','193','201','202','204','206','207','210','211','212','214'\n",
    "          ,'218','244','246','253','256','273','276','297']\n",
    "    \n",
    "    \"\"\"\n",
    "        user_chosen=[]\n",
    "    for item in position:\n",
    "        user_chosen.append(users[item])\n",
    "    \"\"\"\n",
    "        \n",
    "    length=len(new_data)\n",
    "    for i in range(length):\n",
    "        if(new_data[i][0]==users[user]):#这里的user指的是在54个里面的排序\n",
    "            select_data.append(new_data[i][3:])#[5:]\n",
    "            pv_size=float(new_data[i][1])\n",
    "    GC=[]\n",
    "    CL=[]\n",
    "    GG=[]\n",
    "    Length_select_data = len(select_data)\n",
    "    for i in range(Length_select_data):\n",
    "        if(select_data[i][0]=='GC'):\n",
    "            GC.append(select_data[i][2:])\n",
    "        elif(select_data[i][0]=='CL'):\n",
    "            CL.append(select_data[i][2:])\n",
    "        else:\n",
    "            GG.append(select_data[i][2:])\n",
    "            \n",
    "    Total_Load=[]\n",
    "    temp=[]\n",
    "    a=0.0\n",
    "    for i in range(Length_select_data):\n",
    "        if(select_data[i][0]=='GC' and select_data[i+1][0]=='CL'):\n",
    "            for j in range(len(select_data[i][2:])):\n",
    "                a=pd.to_numeric(select_data[i][j+2])+pd.to_numeric(select_data[i+1][j+2])\n",
    "                temp.append(a)\n",
    "            Total_Load.append(temp)\n",
    "        elif(select_data[i][0]=='GC' and select_data[i+1][0]!='CL'):\n",
    "            Total_Load.append(select_data[i][2:])\n",
    "        temp=[]\n",
    "        \n",
    "    GC_temp=np.array(GC)\n",
    "    GC_array=[]\n",
    "    GC_array = GC_temp.astype(np.float)*2\n",
    "\n",
    "    GG_temp=np.array(GG)\n",
    "    GG_array=[]\n",
    "    GG_array = GG_temp.astype(np.float)*2#使单位变成了千瓦\n",
    "    \n",
    "    Total_Load_temp=np.array(Total_Load)\n",
    "    Total_Load_array=[]\n",
    "    Total_Load_array = Total_Load_temp.astype(np.float32)*2#一个小时的功率KW\n",
    "    \n",
    "    return GG_array,Total_Load_array,pv_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##滚动法求24小时的最佳SOC，选取最前一段作为SOC，这里默认充放电功率界限和效率一样\n",
    "def milp_one2(T_tou,T_fit,Total_Load_array,GG_array,bat_state,i,d,pb_bar,bat_max,efficiency_i,efficiency_c,dh,pg_bar):\n",
    "    expression=0\n",
    "    tfit=[]\n",
    "    model = Model()####对变量命名并且给出上下界\n",
    "    var_list = np.arange(0,48,1)\n",
    "    X1 = model.continuous_var_list(var_list,lb=0.0,ub=pg_bar,name='X1')#代表pg_import(pg+)，功率\n",
    "    X2 = model.continuous_var_list(var_list,lb=0.0,ub=pg_bar,name='X2')#代表pg_export(pg-)\n",
    "    Y1 = model.continuous_var_list(var_list,lb=0.0,ub=pb_bar,name='Y1')#代表充电功率（pb+）\n",
    "    Y2 = model.continuous_var_list(var_list,lb=0.0,ub=pb_bar,name='Y2')#代表放电功率（pb-）\n",
    "    dg=model.binary_var_list(var_list,name='dg')#决策变量电网电力流向（0：用户到电网）\n",
    "    sb=model.binary_var_list(var_list,name='sb')#决策变量电池充电状态（0：放电）\n",
    "    eb=model.continuous_var_list(var_list,lb=0,name='eb')#电池容量SOC\n",
    "    tou=[]\n",
    "    tou.extend(T_tou[i:])\n",
    "    tou.extend(T_tou[0:i])#输入分时电价\n",
    "    \n",
    "    for j in range(48):\n",
    "        #tfit.append(T_fit)\n",
    "        expression+=tou[j]*X1[j]*dh#X1为pg+,X2为pg-,Y1为pb+,Y2为pb-\n",
    "        expression-=T_fit*X2[j]*dh\n",
    "    #约束条件（2）\n",
    "        if(j+i<48):#i表示第几个时刻\n",
    "            model.add_constraint(X1[j]-X2[j]-efficiency_i*efficiency_c*Y1[j]+(efficiency_i/efficiency_c)*Y2[j]==\n",
    "                         Total_Load_array[d][j+i]-efficiency_i*GG_array[d][j+i])\n",
    "        else:\n",
    "            model.add_constraint(X1[j]-X2[j]-efficiency_i*efficiency_c*Y1[j]+(efficiency_i/efficiency_c)*Y2[j]==\n",
    "                         Total_Load_array[d+1][j+i-48]-efficiency_i*GG_array[d+1][j+i-48])\n",
    "        \n",
    "    #约束条件（3）\n",
    "        bat_state.append(bat_state[-1]+dh*efficiency_c*Y1[j]-(dh/efficiency_c)*Y2[j])#约束条件（3）\n",
    "        eb[j]=bat_state[-1]\n",
    "        model.add_constraint(eb[j]<=bat_max)#约束条件（12）\n",
    "        model.add_constraint(eb[j]>=0)#约束条件（12）\n",
    "    #约束条件（4）\n",
    "        model.add_constraint(X1[j]-pg_bar*dg[j]<=0)\n",
    "    #约束条件（5）\n",
    "        model.add_constraint(X2[j]+pg_bar*dg[j]<=pg_bar)\n",
    "    #约束条件（6）\n",
    "        model.add_constraint(Y1[j]-pb_bar*sb[j]<=0)\n",
    "    #约束条件（7）\n",
    "        model.add_constraint(Y2[j]+pb_bar*sb[j]<=pb_bar)\n",
    "    model.minimize(expression)#目标函数    \n",
    "    sol = model.solve() #输出解\n",
    "    temp = sol.get_all_values()\n",
    "    return temp,bat_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##对用户进行364天的SOC计算\n",
    "def MILP_365(Total_Load_array,GG_array,user):\n",
    "    L={0: 4,1: 5,2: 4,3: 4,4: 5,5: 5,6: 3,7: 3,8: 5,9: 5,10: 5,11: 8,12: 10,13: 7,14: 5,\n",
    " 15: 5,16: 5,17: 4,18: 4,19: 10,20: 6,21: 5,22: 3,23: 4,24: 5,25: 6,26: 4,27: 9,28: 5,29: 10,\n",
    " 30: 6,31: 5,32: 4,33: 3,34: 4,35: 5,36: 8,37: 5,38: 3,39: 4,40: 5,41: 6,42: 5,43: 4,\n",
    " 44: 5,45: 4,46: 4,47: 5,48: 4,49: 6,50: 9,51: 7,52: 5,53: 4}\n",
    "    #注意这里29和30是作者剔除的，这里考虑进来了\n",
    "    days=364\n",
    "    efficiency_i=0.9\n",
    "    efficiency_c=0.95\n",
    "    dh=0.5\n",
    "    pg_bar=20\n",
    "    T_flat=0.235018\n",
    "    T_fit=0.09\n",
    "    T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]\n",
    "    if(L[user]==3 or L[user]==4):\n",
    "        init_state=6.5\n",
    "        pb_bar=4.2\n",
    "    elif(L[user]==5 or L[user]==6):\n",
    "        init_state=9.8\n",
    "        pb_bar=5\n",
    "    elif(L[user] in [7,8,9,10]):\n",
    "        init_state=14\n",
    "        pb_bar=5\n",
    "        \n",
    "    bat_max=init_state\n",
    "    bat_state=[0.5*init_state]#要输出的电池状态，这是0时刻的初始状态\n",
    "    pg_import=[[] for _ in range(days)]\n",
    "    pg_export=[[] for _ in range(days)]\n",
    "    pb_c=[[] for _ in range(days)]\n",
    "    pb_d=[[] for _ in range(days)]\n",
    "    soc=[[] for _ in range(days)]\n",
    "    soc[0]=[0.5*bat_max]\n",
    "    \n",
    "    for d in np.arange(0,days,1): \n",
    "        for i in range(48):\n",
    "        #print(bat_state)\n",
    "            temp=[]\n",
    "            temp,before=milp_one2(T_tou,T_fit,Total_Load_array,GG_array,bat_state,i,d,pb_bar,bat_max,efficiency_i,efficiency_c,dh,pg_bar)\n",
    "        #print(temp[96])\n",
    "            if(i==47 and d<days-1):\n",
    "                soc[d+1].append(abs(before+dh*efficiency_c*temp[96]-(dh/efficiency_c)*temp[144]))\n",
    "            elif(i<47):     \n",
    "                soc[d].append(abs(before+dh*efficiency_c*temp[96]-(dh/efficiency_c)*temp[144]))#bat_state保存的是滚动域内48个时刻都要满足电池约束，所以一个遍历完后得\n",
    "        #重置，而SOC是要输出的值\n",
    "            bat_state=[]\n",
    "            bat_state.append(soc[d][-1])\n",
    "        #d=bat_state[-1]+0.455*a[0]-(0.5/0.91)*a[0]\n",
    "        #print(bat_state[-1])\n",
    "            pg_import[d].append(abs(temp[0]))\n",
    "            pg_export[d].append(abs(temp[48]))\n",
    "            pb_c[d].append(abs(temp[96]))\n",
    "            pb_d[d].append(abs(temp[144]))\n",
    "    return soc,pg_import,pg_export,pb_c,pb_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将求出的一年的SOC值保存为excel格式，方便以后调用，节约时间\n",
    "def save(data,path):\n",
    "    wb = Workbook()\n",
    "    ws = wb.active # 激活 worksheet\n",
    "    [h, l] = np.array(data).shape  # h为行数，l为列数\n",
    "    for i in range(h):\n",
    "        row = []\n",
    "        for j in range(l):\n",
    "            row.append(format(data[i][j],'.4f'))\n",
    "        ws.append(row)\n",
    "    wb.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GG_array,Total_Load_array,pv_size=Read_yearRNN(2010,13)#之后RNN需后48时刻的SOC以及训练的LABEL都要是以单位为千瓦时的\n",
    "soc,pg_import,pg_export,pb_c,pb_d=MILP_365(Total_Load_array,GG_array,13)\n",
    "path=\"C:/Users/chenxihui/Desktop/code/project/processed_data/2010/socrnn-13-3.xlsx\"\n",
    "save(soc,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取之前保存的SOC值（excel形式的）\n",
    "def read_data(road):\n",
    "    workbook=openpyxl.load_workbook(\"C:/Users/chenxihui/Desktop/code/project/processed_data/2010/\"+road+\".xlsx\")\n",
    "    shenames=workbook.sheetnames\n",
    "    worksheet=workbook.worksheets[0]\n",
    "    name=worksheet.title \n",
    "    rows=worksheet.max_row\n",
    "    columns=worksheet.max_column\n",
    "    data_read=[[] for i in range(rows)]\n",
    "    i=0\n",
    "    for row in worksheet.rows:\n",
    "        for cell in row:\n",
    "            data_read[i].append(cell.value)\n",
    "        i=i+1\n",
    "    data_temp=np.array(data_read)\n",
    "    data_array=[]\n",
    "    data_array=data_temp.astype(np.float)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#为了训练RNN做的336维的数据集，大的数据集，包含了训练集和测试集\n",
    "def samples(T_tou,soc_y,Total_Load_array,GG_array):\n",
    "    #此版本为362天的样本数据点集合,从第一天开始算，但第一天里都是空集合，从第二天开始有数值\n",
    "    T_tou_temp=[]\n",
    "    for i in range(3):\n",
    "        T_tou_temp.extend(T_tou)\n",
    "    days=365    \n",
    "    data_365=[[[] for _ in range(48)] for _ in range(days)]\n",
    "    for d in range(days):\n",
    "        for i in range(48):\n",
    "            data_temp=[]\n",
    "            GG_temp=[]\n",
    "            soc_temp=[]#前48个SOC（包含当前时刻）\n",
    "            ToU_temp=[]\n",
    "            load_temp=[]\n",
    "            if(d<363 and d>0):\n",
    "                if(i==47):\n",
    "                    soc_temp=soc_y[d]#soc_y是MILP的结果，从第一天开始的\n",
    "                    ToU_temp=np.hstack((T_tou,T_tou))\n",
    "                    load_temp=np.hstack((Total_Load_array[d],Total_Load_array[d+1]))\n",
    "                    GG_temp=np.hstack((GG_array[d],GG_array[d+1]))\n",
    "                else:\n",
    "                    soc_temp=np.hstack((soc_y[d-1][i+1:],soc_y[d][:i+1]))\n",
    "                    ToU_temp=np.hstack((T_tou[i+1:],T_tou,T_tou[:i+1]))\n",
    "                    GG_temp=np.hstack((GG_array[d-1][i+1:],GG_array[d],GG_array[d+1][:i+1]))#难道d+1是\n",
    "                    load_temp=np.hstack((Total_Load_array[d-1][i+1:],Total_Load_array[d],Total_Load_array[d+1][:i+1]))\n",
    "            data_temp=soc_temp\n",
    "            data_temp=np.hstack((data_temp,ToU_temp))\n",
    "            data_temp=np.hstack((data_temp,list(map(float, GG_temp))))\n",
    "            data_temp=np.hstack((data_temp,load_temp))\n",
    "            data_365[d][i]=data_temp\n",
    "    return data_365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成训练RNN的训练集前300天\n",
    "def generate_train(year,user):\n",
    "    T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]\n",
    "    \n",
    "    GG_array,Total_Load_array,pv_size=Read_year(year,user)\n",
    "    soc_y=read_data(\"soc-\"+str(user)+\"-4\")#单位为千瓦时\n",
    "    soc_y=[i*2 for i in soc_y]#转换为千瓦\n",
    "    data_365=samples(T_tou,soc_y,Total_Load_array,GG_array)\n",
    "    a=np.array(data_365[1:302]).transpose((1,0,2))\n",
    "    soc_label=[[]for i in range(360)]\n",
    "    for i in range(360):\n",
    "        for j in np.arange(1,48):\n",
    "            soc_label[i].append(soc_y[i+1][j])#因为label是下一时刻的SOC，所以从1开始\n",
    "        soc_label[i].append(soc_y[i+2][0])\n",
    "    return a,soc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 此为300天-340天数据作为同一用户的测试集\n",
    "def generate_test(year,user):\n",
    "    T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]\n",
    "    GG_array,Total_Load_array,pv_size=Read_year(year,user)\n",
    "    soc_y=read_data(\"soc-\"+str(user)+\"-4\")\n",
    "    soc_y=[i*2 for i in soc_y]#转换为千瓦\n",
    "    data_365=samples(T_tou,soc_y,Total_Load_array,GG_array)\n",
    "    \n",
    "    test=np.array(data_365[1:361]).transpose((1,0,2))#测试集从第302天开始\n",
    "    \n",
    "    soc_label=[[]for i in range(360)]\n",
    "    for i in range(360):\n",
    "        for j in np.arange(1,48):\n",
    "            soc_label[i].append(soc_y[i+1][j])\n",
    "        soc_label[i].append(soc_y[i+2][0])\n",
    "    return test,soc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RNN的测试，对自己本身\n",
    "def RNN_test(year,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func):    \n",
    "    print(\"Testing...load model...\")\n",
    "    filepath = \"./model/rnn\"+str(year)+\"-\"+str(user)+\".model\"\n",
    "    checkpoint = torch.load(filepath)\n",
    "    rnn.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    rnn.eval()\n",
    "    \n",
    "    test,soc_label=generate_test(year,user)\n",
    "    testloss=0\n",
    "    with torch.no_grad():\n",
    "        for step in range(40):\n",
    "            test_x=torch.from_numpy(np.array(test[:,step,np.newaxis])).float().to(device)\n",
    "            test_y = torch.from_numpy(np.array(soc_label[step])[:,np.newaxis,np.newaxis]).float().to(device)\n",
    "            predict, h_state = rnn(test_x,h_state)\n",
    "            loss_test = loss_func(predict, test_y)\n",
    "            testloss+=loss_test\n",
    "    print(str(user)+\"testloss：\"+str(testloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN网络的训练\n",
    "def RNN_train(year,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func):\n",
    "    rnn.train()\n",
    "    a,soc_label = generate_train(year,user)\n",
    "    train_loss=[]\n",
    "    lr_list = []\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50,100,150,200,250,300], gamma=0.6)\n",
    "    max_loss,min_loss=0,20\n",
    "    for step in range(N_EPOCHS):\n",
    "        error=0.0\n",
    "        for batch_num in range(batch_nums):#此处分成了301个batch \n",
    "            x=torch.from_numpy(np.array(a[:,batch_num,np.newaxis])).float().to(device)\n",
    "            #print(x.size())48*1*336\n",
    "            y=torch.from_numpy(np.array(soc_label[batch_num])[:,np.newaxis,np.newaxis]).float().to(device)\n",
    "            #print(y.size())48*1*1\n",
    "            x=x.cuda()\n",
    "            y=y.cuda()\n",
    "            optimizer.zero_grad()#清零，模型的参数梯度设成0\n",
    "            prediction, h_state = rnn(x, h_state)  # RNN输出（预测结果，隐藏状态）\n",
    "            #print(prediction.size())48*1*1\n",
    "            h_state = h_state.detach()  # 这一行很重要，将每一次输出的中间状态传递下去(不带梯度)，将h_state分离出来，同时不影响后向计算        \n",
    "            \n",
    "            loss,temp_loss=0,0\n",
    "            for i in range(48):\n",
    "                temp_loss=abs(prediction[i][0][0]-y[i][0][0])\n",
    "                if(temp_loss>max_loss):#得到预测误差最大\n",
    "                    max_loss=temp_loss\n",
    "                if(temp_loss<min_loss):#得到误差最小\n",
    "                    min_loss=temp_loss\n",
    "                loss+=temp_loss\n",
    "            loss=loss/48\n",
    "            \n",
    "            #loss = loss_func(prediction, y)\n",
    "            error += loss\n",
    "            optimizer.zero_grad()#清零，模型的参数梯度设成0\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # 学习率更新\n",
    "            lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "            #torch.save(rnn.state_dict(), 'C:/Users/chenxihui/Desktop/code/project/rnn.pt')\n",
    "        error /= batch_nums\n",
    "        train_loss.append(error)\n",
    "    print(str(user)+\"  train Loss = \" + str(error))#输出最后一个epoch输出的loss\n",
    "    print(str(user)+\"  train max Loss = \" + str(max_loss))\n",
    "    print(str(user)+\"  train min Loss = \" + str(min_loss))\n",
    "    \n",
    "    if not os.path.exists(\"./model/\"):\n",
    "        os.makedirs(\"./model/\")\n",
    "    filepath = \"./model/rnnkw\"+str(year)+\"-\"+str(user)+\".model\"\n",
    "    torch.save({\"model_state_dict\" : rnn.state_dict(),\n",
    "            \"optimizer_state_dict\" : optimizer.state_dict()},\n",
    "            filepath)   \n",
    "    #print(\"Model has been saved.\")\n",
    "    #return train_loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "###step 4：对每个用户训练出的模型进行测试（在其他用户身上）\n",
    "def model_test(year,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func,position):\n",
    "\n",
    "    print(\"Testing...load model...\")\n",
    "    filepath = \"./model/rnnkw\"+str(year)+\"-\"+str(user)+\".model\"\n",
    "    checkpoint = torch.load(filepath)\n",
    "    rnn.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    rnn.eval()\n",
    "    dayloss=[]\n",
    "    testloss=0\n",
    "    max_loss,min_loss=0,20\n",
    "    for num in position:\n",
    "        test,soc_label=generate_test(2010,num)\n",
    "        with torch.no_grad():\n",
    "            for step in range(360):\n",
    "                loss_test=0\n",
    "                test_x=torch.from_numpy(np.array(test[:,step,np.newaxis])).float().to(device)\n",
    "                test_y = torch.from_numpy(np.array(soc_label[step])[:,np.newaxis,np.newaxis]).float().to(device)\n",
    "                predict, h_state = rnn(test_x,h_state)\n",
    "                loss,temp_loss=0,0\n",
    "                for i in range(48):\n",
    "                    temp_loss=abs(predict[i][0][0]-test_y[i][0][0])\n",
    "                    if(temp_loss>max_loss):#得到预测误差最大\n",
    "                        max_loss=temp_loss\n",
    "                    if(temp_loss<min_loss):#得到误差最小\n",
    "                        min_loss=temp_loss\n",
    "                    loss+=temp_loss\n",
    "                dayloss.append(loss)\n",
    "                loss=loss/48\n",
    "                #loss_test = loss_func(predict, test_y)#MAE 48个时刻的误差绝对值的平均值，个数是按照【】的个数，不是按照元素的个数\n",
    " #               p=np.array(predict.tolist())\n",
    " #               y=np.array(test_y.tolist())\n",
    " #               for i in range(len(p)):\n",
    " #                   loss_test+=abs(p[i]-y[i])\n",
    "                testloss+=loss\n",
    "    testloss=testloss/(len(position)*360)\n",
    "    print(\"Test has been done! The LOSS is: \"+str(testloss))\n",
    "    print(str(user)+\"  test max Loss = \" + str(max_loss))\n",
    "    print(str(user)+\"  test min Loss = \" + str(min_loss))\n",
    "    print(str(user)+\"  testday min Loss = \" + str(min(dayloss)))\n",
    "    print(str(user)+\"  testday max Loss = \" + str(max(dayloss)))\n",
    "    return testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  train Loss = tensor(0.7574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "12  train max Loss = tensor(28.0553, device='cuda:0', grad_fn=<AbsBackward>)\n",
      "12  train min Loss = tensor(0., device='cuda:0', grad_fn=<AbsBackward>)\n"
     ]
    }
   ],
   "source": [
    "position=[12]#特征模型用户为82\n",
    "get_indicator(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...load model...\n",
      "Test has been done! The LOSS is: tensor(0.9745, device='cuda:0')\n",
      "12  test max Loss = tensor(11.8118, device='cuda:0')\n",
      "12  test min Loss = tensor(0.0003, device='cuda:0')\n",
      "12  testday min Loss = tensor(9.6042, device='cuda:0')\n",
      "12  testday max Loss = tensor(87.2502, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "position=[12]#特征模型用户为82\n",
    "get_indicator(position) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从类中返回该类的特征模型，position为一类\n",
    "def get_indicator(position):\n",
    "    ###超参数设置\n",
    "    year=2010\n",
    "    TIME_STEP = 48  # RNN时间步长\n",
    "    INPUT_SIZE = 336  # RNN输入尺寸\n",
    "    INIT_LR = 0.01  # 初始学习率\n",
    "    N_EPOCHS = 300  # 训练回数\n",
    "    Batch_size=1\n",
    "    batch_nums=301\n",
    "    train_loss,test_loss=[],[]\n",
    "    ### RNN建立\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    class RNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(RNN, self).__init__()\n",
    "            self.rnn = nn.RNN(\n",
    "                input_size=INPUT_SIZE,\n",
    "                hidden_size=20,  # RNN隐藏神经元个数20\n",
    "                num_layers=1,  # RNN隐藏层个数\n",
    "            )\n",
    "            self.out = nn.Linear(20, 1)#全连接层\n",
    "\n",
    "        def forward(self, x, h):\n",
    "            out, h = self.rnn(x, h)\n",
    "            prediction = self.out(out)\n",
    "            return prediction, h\n",
    "    \n",
    "    ###step 1：得到分类结果，给出属于同一类的用户标号\n",
    "    #position=[1,3,6,12,14,15,16,18,19,22,23,26,28,31,32,34,38,41,42,43,45,46,47]\n",
    "    scores=[]\n",
    "    ###step 2：处理该类中MILP、SOC，为了节约时间，将他们先处理保存，之后读取即可\n",
    "    #for user in position:\n",
    "        #GG_array,Total_Load_array,pv_size=Read_year(year,user)\n",
    "        #soc,pg_import,pg_export,pb_c,pb_d=MILP_365(Total_Load_array,GG_array,user)\n",
    "    ###step 3：对每个用户训练一个模型\n",
    "    for user in position:\n",
    "        rnn = RNN().to(device)\n",
    "        optimizer = torch.optim.Adam(rnn.parameters(), lr=INIT_LR)\n",
    "        loss_func = nn.L1Loss()\n",
    "        h_state = None #之前没有这个导致前一个用户的训练影响后一个用户了\n",
    "        #RNN_train(2010,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func)\n",
    "        #RNN_test(2010,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func)\n",
    "    ###step 4：对每个用户训练出的模型进行测试（在其他用户身上）\n",
    "      \n",
    "        testloss=model_test(year,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func,position)\n",
    "        #print(str(user)+\" : \"+str(testloss))\n",
    "        #scores.append(testloss)\n",
    "    ###step 5:选出类的特征模型\n",
    " #  minscore=2000\n",
    " #  for i in range(len(scores)):\n",
    " #      if(minscore>scores[i]):\n",
    " #          minscore=scores[i]\n",
    " #  for i in range(len(scores)):\n",
    " #      if(minscore==scores[i]):\n",
    " #          return position[i]#得到该类中的特征模型的用户编号\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHENXI~1\\AppData\\Local\\Temp/ipykernel_8904/335794313.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#为节省时间，运行一遍后将数据保存直接用\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfinal_center\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mposition1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mposition2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mposition3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mposition4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mposition5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcluster_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2010\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\CHENXI~1\\AppData\\Local\\Temp/ipykernel_8904/2635322207.py\u001b[0m in \u001b[0;36mcluster_result\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#返回对所有用户聚类的结果，以及类中心曲线\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcluster_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mTotal_Load\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcluster_allload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_center\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_means\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTotal_Load\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;31m# so, we need to show it in list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\CHENXI~1\\AppData\\Local\\Temp/ipykernel_8904/2526570445.py\u001b[0m in \u001b[0;36mcluster_allload\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'GC'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mselect_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'CL'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                 \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mTotal_Load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             values = lib.maybe_convert_numeric(\n\u001b[1;32m--> 153\u001b[1;33m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m             )\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#为节省时间，运行一遍后将数据保存直接用\n",
    "final_center,position1,position2,position3,position4,position5=cluster_result(2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCM(load,GG,pb_bar,bat_max):#这里的输入单位也是功率值KW，所以在算用电成本时需要乘上dh，即0.5\n",
    "    bat_min,eff_i,eff_c,dh,pg_bar=0,0.9,0.95,0.5,np.max(load)\n",
    "    pg_import,pg_export,pb_c,pb_d,pb_res,soc,e_b,eb_res,p_res=[],[],[],[],[],[],[0.5*bat_max],[],[]\n",
    "    for d in np.arange(0,14,1):#天数设置\n",
    "        for i in range(48):\n",
    "            p_res.append(GG[d][i]*eff_i-load[d][i])\n",
    "            #print(p_res[-1])\n",
    "            #print(i)\n",
    "            if(p_res[-1]>0.0):#发电量能满足需求的情况\n",
    "                eb_res.append(bat_max-e_b[-1])\n",
    "                #print(eb_res[-1])\n",
    "                if(eb_res[-1]>0.0):#电池还能充电\n",
    "                    #pb_c设置为pb_bar、p_res、将电池充满需要的电量中的最小值\n",
    "                    pb_c.append(min(pb_bar,min(abs(p_res[-1])/(eff_i*eff_c),(eb_res[-1])/(dh*eff_c))))#此处改动原文eb_res[-1]/(dh*eff_c)\n",
    "                    pg_export.append(abs(p_res[-1])-pb_c[-1]*eff_i*eff_c)#发电量满足充电后，卖电与eff_i有关\n",
    "                    pb_d.append(0)#不放电\n",
    "                    pg_import.append(0)#不用买电\n",
    "                else:#电池满了，不能充电的情况\n",
    "                    pg_export.append(abs(p_res[-1]))#直接卖电\n",
    "                    pg_import.append(0)#不买电\n",
    "                    pb_d.append(0)#不充电\n",
    "                    pb_c.append(0)#不放电\n",
    "            elif(p_res[-1]<0.0):#发电量不能满足需求的情况\n",
    "                eb_res.append(e_b[-1]-bat_min)#电池可以放的电量\n",
    "                #print(eb_res[-1])\n",
    "                if(eb_res[-1]<0.01):#电池没电的情况\n",
    "                    pg_import.append(abs(p_res[-1]))#买电，满足需求\n",
    "                    pg_export.append(0)\n",
    "                    pb_d.append(0)\n",
    "                    pb_c.append(0)\n",
    "                else:#电池有电的情况\n",
    "                    pb_d.append(min(pb_bar,min(abs(p_res[-1])*eff_c/eff_i,(eb_res[-1]*eff_c)/(dh))))#放到电池外面的电\n",
    "                    pb_c.append(0)\n",
    "                    pg_import.append((abs(p_res[-1])-pb_d[-1]*eff_i/eff_c))#应该是买电，论文中的算法有错误\n",
    "                    pg_export.append(0)\n",
    "            else:\n",
    "                pg_import.append(0.0)\n",
    "                pg_export.append(0.0)\n",
    "                pb_c.append(0.0)\n",
    "                pb_d.append(0.0)\n",
    "            e_b.append(e_b[-1]+dh*(eff_c*pb_c[-1]-pb_d[-1]/eff_c))\n",
    "    return pg_import,pg_export,pb_c,pb_d,e_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RNN的测试，对自己本身\n",
    "year=2010\n",
    "TIME_STEP = 48  # RNN时间步长\n",
    "INPUT_SIZE = 336  # RNN输入尺寸\n",
    "INIT_LR = 0.01  # 初始学习率\n",
    "N_EPOCHS = 300  # 训练回数\n",
    "Batch_size=1\n",
    "batch_nums=301\n",
    "train_loss,test_loss=[],[]\n",
    "    ### RNN建立\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=20,  # RNN隐藏神经元个数20\n",
    "            num_layers=1,  # RNN隐藏层个数\n",
    "            )\n",
    "        self.out = nn.Linear(20, 1)#全连接层\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        out, h = self.rnn(x, h)\n",
    "        prediction = self.out(out)\n",
    "        return prediction, h\n",
    "    \n",
    "rnn = RNN().to(device)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=INIT_LR)\n",
    "loss_func = nn.L1Loss()\n",
    "h_state = None \n",
    "\n",
    "def online(year,cluster_indicator,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func,point):    \n",
    "    #print(\"Starting...\")\n",
    "    #print(point)\n",
    "    filepath = \"./model/rnn\"+str(year)+\"-\"+str(cluster_indicator)+\".model\"#这里读取的是类特征模型\n",
    "    checkpoint = torch.load(filepath)\n",
    "    rnn.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    rnn.eval()   #进入测试模式，权重不变\n",
    "    #生成输入\n",
    "    with torch.no_grad():\n",
    "        #print(np.array(point[np.newaxis,np.newaxis,:]).shape)\n",
    "        x=torch.from_numpy(np.array(point[np.newaxis,np.newaxis,:])).float().to(device)\n",
    "        predict, h_state = rnn(x,h_state)\n",
    "    return predict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "sample = torch.tensor([[[1.,2],[1.,2]],[[1.,2],[1.,2]]])\n",
    "target = torch.tensor([[[0.,0],[1.,0]],[[2.,0],[3.,0]]])\n",
    "criterion = nn.L1Loss()\n",
    "loss = criterion(sample, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  error:0  cost: 402.3556608808183\n"
     ]
    }
   ],
   "source": [
    "year=2010\n",
    "#position3=[5, 8, 13, 24, 25, 27, 29, 30, 44, 50, 52]#[4, 5, 8, 13, 25, 27, 29, 30, 44, 50, 52]\n",
    "#position4=[1,3,6,12,14,15,16,18,19,22,23,26,28,31,32,34,38,41,42,43,45,46,47]\n",
    "#position2=[17, 51]\n",
    "#position5=[2, 7, 20, 36, 39, 40, 48]\n",
    "#position1=[0, 4, 9, 10, 11, 21, 33, 35, 37, 49, 53]\n",
    "position1=[12]\n",
    "cluster_indicator=12\n",
    "cost1=[]\n",
    "#theta=[0.025,0.05,0.1]\n",
    "theta=[0]\n",
    "T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]\n",
    "for user in position1:\n",
    "    #GG_array,Total_Load_array,pv_size=Read_yearRNN(year,user)\n",
    "    GG_array,Total_Load_array,pv_sizeMILP=Read_year(year,user)\n",
    "    for error in theta: \n",
    "        soc_milp,pg_import_milp,pg_export_milp,pb_c_milp,pb_d_milp=MILP2(Total_LoadMILP,GG_arrayMILP,user)\n",
    "        #soc_milp3,pg_import_milp3,pg_export_milp3,pb_c_milp3,pb_d_milp3=MILP2ip(Total_Load_array,GG_array,user,i)\n",
    "        #pg_import,pg_export=PFA(year,user,cluster_indicator,GG_array,Total_Load_array,error)\n",
    "        T_tou1=[]#PFA PP\n",
    "        pg_import2,pg_export2,pb_c2,pb_d2=[],[],[],[]\n",
    "        for i in np.arange(14,360,1):\n",
    "            T_tou1.extend(T_tou)\n",
    "            pg_import2.extend(pg_import_milp[i])\n",
    "            pg_export2.extend(pg_export_milp[i])\n",
    "\n",
    "        cost,dh,T_fit=0,0.5,0.09\n",
    "        for i in range(len(pg_import2)):\n",
    "            cost+=float(np.array(pg_import2[i]))*T_tou1[i]*dh-float(np.array(pg_export2[i]))*T_fit*dh\n",
    "        print(str(user)+\"  error:\"+str(error)+\"  cost: \"+str(cost))\n",
    "        #cost1.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  error:0  cost: 2167.349359390805\n"
     ]
    }
   ],
   "source": [
    "year=2010\n",
    "#position3=[5, 8, 13, 24, 25, 27, 29, 30, 44, 50, 52]#[4, 5, 8, 13, 25, 27, 29, 30, 44, 50, 52]\n",
    "#position4=[1,3,6,12,14,15,16,18,19,22,23,26,28,31,32,34,38,41,42,43,45,46,47]\n",
    "#position2=[17, 51]\n",
    "#position5=[2, 7, 20, 36, 39, 40, 48]\n",
    "#position1=[0, 4, 9, 10, 11, 21, 33, 35, 37, 49, 53]\n",
    "position1=[13]\n",
    "cluster_indicator=13\n",
    "cost1=[]\n",
    "theta=[0]\n",
    "T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]\n",
    "for user in position1:\n",
    "    #GG_array,Total_Load_array,pv_size=Read_yearRNN(year,user)\n",
    "    #GG_arrayMILP,Total_LoadMILP,pv_sizeMILP=Read_yearMILP(year,user)\n",
    "    for error in theta: \n",
    "        #soc_milp,pg_import_milp,pg_export_milp,pb_c_milp,pb_d_milp=MILP2(Total_LoadMILP,GG_arrayMILP,user)\n",
    "        #soc_milp3,pg_import_milp3,pg_export_milp3,pb_c_milp3,pb_d_milp3=MILP2ip(Total_Load_array,GG_array,user,i)\n",
    "        #pg_import,pg_export=PFA(year,user,cluster_indicator,GG_array,Total_Load_array,error)\n",
    "        T_tou1=[]#PFA PP\n",
    "        #pg_import2,pg_export2,pb_c2,pb_d2=[],[],[],[]\n",
    "        for i in np.arange(14,360,1):\n",
    "            T_tou1.extend(T_tou)\n",
    "            pg_import2.extend(pg_import[i])\n",
    "            pg_export2.extend(pg_export[i])\n",
    "\n",
    "        cost,dh,T_fit=0,0.5,0.09\n",
    "        for i in range(len(pg_import2)):\n",
    "            cost+=float(np.array(pg_import2[i]))*T_tou1[i]*dh-float(np.array(pg_export2[i]))*T_fit*dh\n",
    "        print(str(user)+\"  error:\"+str(error)+\"  cost: \"+str(cost))\n",
    "        #cost1.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分完类后对用户执行线上执行策略，执行前得做输入数据集\n",
    "    #cluster_indicator=indicators[newuser_cluster]\n",
    "def PFA(year,user,cluster_indicator,GG_array,Total_Load_array,theta):\n",
    "    #cluster_indicator=indicators[newuser_cluster]\n",
    "    #user=cluster_indicator  # 13，\"82\"\n",
    "    #GG_array,Total_Load_array,pv_size=Read_year(year,user)#USER[13]=82\n",
    "    #soc_milp,pg_import_milp,pg_export_milp,pb_c_milp,pb_d_milp=MILP2(Total_Load_array,GG_array,user)\n",
    "    T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "           0.38588,0.38588, 0.38588,0.38588, \n",
    "          0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "          0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "          0.37147,0.37147,0.37147,0.37147,\n",
    "          0.2134,0.2134,0.2134,0.2134]\n",
    "    days=365\n",
    "    eff_i,eff_c,dh,bat_min,T_flat,T_fit=0.9,0.95,0.5,0,0.235,0.09\n",
    "    points365=[[[] for _ in range(48)] for _ in range(days)]\n",
    "    pg_import=[[0 for i in range(48)] for _ in range(days)]\n",
    "    pg_export=[[0 for i in range(48)] for _ in range(days)]\n",
    "    pb_c=[[0 for i in range(48)] for _ in range(days)]\n",
    "    pb_d=[[0 for i in range(48)] for _ in range(days)]\n",
    "    L={0: 4,1: 5,2: 4,3: 4,4: 5,5: 5,6: 3,7: 3,8: 5,9: 5,10: 5,11: 8,12: 10,13: 7,14: 5,\n",
    "     15: 5,16: 5,17: 4,18: 4,19: 10,20: 6,21: 5,22: 3,23: 4,24: 5,25: 6,26: 4,27: 9,28: 5,29: 10,\n",
    "     30: 6,31: 5,32: 4,33: 3,34: 4,35: 5,36: 8,37: 5,38: 3,39: 4,40: 5,41: 6,42: 5,43: 4,\n",
    "     44: 5,45: 4,46: 4,47: 5,48: 4,49: 6,50: 9,51: 7,52: 5,53: 4}\n",
    "    pg_bar=20\n",
    "    if(L[user]==3 or L[user]==4):\n",
    "        init_state=6.5\n",
    "        pb_bar=4.2\n",
    "    elif(L[user]==5 or L[user]==6):\n",
    "        init_state=9.8\n",
    "        pb_bar=5\n",
    "    elif(L[user] in [7,8,9,10]):\n",
    "        init_state=14\n",
    "        pb_bar=5\n",
    "    bat_max=init_state\n",
    "    bat_min=0\n",
    "    \n",
    "    pgi_scm,pgo_scm,pb_cscm,pb_dscm,e_bscm=SCM(Total_Load_array,GG_array,pb_bar,bat_max)\n",
    "    e_bscm=[i*2 for i in e_bscm]#将单位转换为千瓦\n",
    "    #soc=read_data(\"soc-\"+str(user)+\"-3\")\n",
    "    soc,pg_import,pg_export,pb_c,pb_d=MILP2(Total_Load_array,GG_array,user)#这是从第14天开始算的，是一维的数组\n",
    "    soc=[i*2 for i in soc]\n",
    "    pred=[e_bscm[671]]#0，第14天最后一个时段\n",
    "    soc_init=e_bscm[623:671]\n",
    "    loss=0\n",
    "    losspoint,lossday=[],[]\n",
    "    #soc_y=read_data(\"soc-\"+str(13)+\"-3\")\n",
    "    for d in np.arange(14,360,1):#346\n",
    "        loss_temp=0\n",
    "        for i in range(48):#！！！！！要做出决策的时段\n",
    "    #从用户第三个星期开始运行\n",
    "    #制作线上执行模型的第一个点336维,第15天的0:30\n",
    "            data_temp,GG_temp,soc_temp,ToU_temp,load_temp=[],[],[],[],[]#前48个SOC（包含当前时刻）\n",
    "            for j in range(47):\n",
    "                soc_init[j]=soc_init[j+1]#e_bscm[624:671]\n",
    "            if(d==14 and i==0):\n",
    "                soc_init[47]=pred[-1]\n",
    "            else:\n",
    "                soc_init[47]=pred[-1]*2#SOC更新\n",
    "                \n",
    "            if(i==0):\n",
    "                ToU_temp=np.hstack((T_tou,T_tou))\n",
    "                GG_temp=np.hstack((GG_array[d-1],[j+np.random.uniform(-theta*j, theta*j) for j in GG_array[d]]))\n",
    "                load_temp=np.hstack((Total_Load_array[d-1],[j+np.random.uniform(-theta*j, theta*j) for j in Total_Load_array[d]]))\n",
    "                #load_temp=np.hstack((Total_Load_array[d-1],Total_Load_array[d-7]))\n",
    "            else:\n",
    "                ToU_temp=np.hstack((T_tou[i:],T_tou,T_tou[:i]))\n",
    "                GG_temp=np.hstack((GG_array[d-1][i:],GG_array[d],GG_array[d+1][:i]))#难道d+1是\n",
    "                for j in np.arange(48,96,1):\n",
    "                    GG_temp[j]=GG_temp[j]+np.random.uniform(-theta*GG_temp[j], theta*GG_temp[j])#*GG_temp[j]\n",
    "                load_temp=np.hstack((Total_Load_array[d-1][i:],Total_Load_array[d][:i],\n",
    "                                     [j+np.random.uniform(-theta*j, theta*j) for j in Total_Load_array[d][i:]],\n",
    "                                     [j+np.random.uniform(-theta*j, theta*j) for j in Total_Load_array[d+1][:i]]))\n",
    "                #load_temp=np.hstack((Total_Load_array[d-1][i:],Total_Load_array[d][:i],\n",
    "                                     #Total_Load_array[d-7][i:],Total_Load_array[d+1-7][:i]))\n",
    "            data_temp=soc_init\n",
    "            data_temp=np.hstack((data_temp,ToU_temp))\n",
    "            data_temp=np.hstack((data_temp,list(map(float, GG_temp))))\n",
    "            data_temp=np.hstack((data_temp,load_temp))\n",
    "            points365[d][i]=data_temp#线上执行策略时数据的输入\n",
    "    #返回线上执行预测的\n",
    "            predict=online(year,cluster_indicator,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func,points365[d][i]).item()\n",
    "            soc_before=pred[-1]\n",
    "            if(predict>bat_max or abs(predict-soc_before)>pb_bar):#预测结果有风险的情况\n",
    "                pg_import,pg_export,pb_c,pb_d,pred=SCM2(Total_Load_array,GG_array,pg_import,pg_export,pb_c,pb_d,pb_bar,bat_max,bat_min,eff_i,eff_c,dh,pg_bar,pred,d,i,theta)\n",
    "            else:#预测结果没问题的情况\n",
    "                pg_import,pg_export,pb_c,pb_d=update(predict,GG_temp,load_temp,user,GG_array,Total_Load_array,d,i,pred\n",
    "                  ,pg_import,pg_export,pb_c,pb_d,bat_max,eff_i,eff_c,dh,theta)\n",
    "                pred.append(predict)\n",
    "            loss_temp+=abs(pred[-1]-soc[(d-14)*48+i+1])\n",
    "            if(i==47):\n",
    "                lossday.append(loss_temp)\n",
    "            loss+=abs(pred[-1]-soc[(d-14)*48+i+1])\n",
    "            losspoint.append(abs((pred[-1]-soc[(d-14)*48+i+1])))\n",
    "    print(str(user)+\"  PFA total Loss = \" + str(loss))\n",
    "    print(str(user)+\"  test max Loss = \" + str(max(losspoint)))\n",
    "    print(str(user)+\"  test min Loss = \" + str(min(losspoint)))\n",
    "    print(str(user)+\"  testday min Loss = \" + str(min(lossday)))\n",
    "    print(str(user)+\"  testday max Loss = \" + str(max(lossday)))\n",
    "    return pg_import,pg_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function OutputStream.__del__ at 0x000002AE9CA94488>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\chenxihui\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\cplex\\_internal\\_ostream.py\", line 96, in __del__\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soc_y=read_data(\"soc-\"+str(13)+\"-3\")\n",
    "soc_y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##对用户进行364天的SOC计算\n",
    "def MILP2(Total_Load_array,GG_array,user):\n",
    "    L={0: 4,1: 5,2: 4,3: 4,4: 5,5: 5,6: 3,7: 3,8: 5,9: 5,10: 5,11: 8,12: 10,13: 7,14: 5,\n",
    " 15: 5,16: 5,17: 4,18: 4,19: 10,20: 6,21: 5,22: 3,23: 4,24: 5,25: 6,26: 4,27: 9,28: 5,29: 10,\n",
    " 30: 6,31: 5,32: 4,33: 3,34: 4,35: 5,36: 8,37: 5,38: 3,39: 4,40: 5,41: 6,42: 5,43: 4,\n",
    " 44: 5,45: 4,46: 4,47: 5,48: 4,49: 6,50: 9,51: 7,52: 5,53: 4}\n",
    "    #注意这里29和30是作者剔除的，这里考虑进来了\n",
    "    \n",
    "    days=364\n",
    "    efficiency_i=0.9\n",
    "    efficiency_c=0.95\n",
    "    dh=0.5\n",
    "    pg_bar=20\n",
    "    T_flat=0.235018\n",
    "    T_fit=0.09\n",
    "    T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]\n",
    "    if(L[user]==3 or L[user]==4):\n",
    "        init_state=6.5\n",
    "        pb_bar=4.2\n",
    "    elif(L[user]==5 or L[user]==6):\n",
    "        init_state=9.8\n",
    "        pb_bar=5\n",
    "    elif(L[user] in [7,8,9,10]):\n",
    "        init_state=14\n",
    "        pb_bar=5\n",
    "        \n",
    "    bat_max=init_state\n",
    "    #bat_state=[0.5*init_state]#要输出的电池状态，这是0时刻的初始状态\n",
    "    bat_state=[0]\n",
    "    pg_import=[[0 for i in range(48)] for _ in range(days)]\n",
    "    pg_export=[[0 for i in range(48)] for _ in range(days)]\n",
    "    pb_c=[[0 for i in range(48)] for _ in range(days)]\n",
    "    pb_d=[[0 for i in range(48)] for _ in range(days)]\n",
    "    soc=[]#电池状态用一维数组接收\n",
    "    #soc[0]=[0.5*bat_max]\n",
    "    soc.append(0)#0是初试的\n",
    "    \n",
    "    for d in np.arange(14,360,1): \n",
    "        for i in range(48):\n",
    "        #print(bat_state)\n",
    "            temp=[]\n",
    "            temp,before=milp_one2(T_tou,T_fit,Total_Load_array,GG_array,bat_state,i,d,pb_bar,bat_max,efficiency_i,efficiency_c,dh,pg_bar)\n",
    "        #print(temp[96])\n",
    "            soc.append(before+dh*efficiency_c*temp[96]-(dh/efficiency_c)*temp[144])#bat_state保存的是滚动域内48个时刻都要满足电池约束，所以一个遍历完后得\n",
    "        #重置，而SOC是要输出的值\n",
    "            bat_state=[]\n",
    "            bat_state.append(soc[-1])\n",
    "        #d=bat_state[-1]+0.455*a[0]-(0.5/0.91)*a[0]\n",
    "        #print(bat_state[-1])\n",
    "            pg_import[d][i]=(abs(temp[0]))\n",
    "            pg_export[d][i]=(abs(temp[48]))\n",
    "            pb_c[d][i]=(abs(temp[96]))\n",
    "            pb_d[d][i]=(abs(temp[144]))\n",
    "    return soc,pg_import,pg_export,pb_c,pb_d\n",
    "\n",
    "def SCM2(load,GG,pg_import,pg_export,pb_c,pb_d,pb_bar,bat_max,bat_min,eff_i,eff_c,dh,pg_bar,pred,d,i,theta):\n",
    "    p_res=GG[d][i]*eff_i-load[d][i]\n",
    "    if(p_res>0.0):#发电量能满足需求的情况\n",
    "        eb_res=bat_max-pred[-1]\n",
    "        if(eb_res>0.0):#电池还能充电\n",
    "            #pb_c设置为pb_bar、p_res、将电池充满需要的电量中的最小值\n",
    "            pb_c[d][i]=min(pb_bar,min(abs(p_res)*eff_i,(eb_res)/(dh*eff_c)))#此处改动原文eb_res[-1]/(dh*eff_c)\n",
    "            pg_export[d][i]=abs(p_res)-pb_c[d][i]/eff_i#发电量满足充电后，卖电与eff_i有关\n",
    "            pb_d[d][i]=(0)#不放电\n",
    "            pg_import[d][i]=(0)#不用买电\n",
    "        else:#电池满了，不能充电的情况\n",
    "            pg_export[d][i]=(abs(p_res))#直接卖电\n",
    "            pg_import[d][i]=(0)#不买电\n",
    "            pb_d[d][i]=(0)#不充电\n",
    "            pb_c[d][i]=(0)#不放电\n",
    "    elif(p_res<0.0):#发电量不能满足需求的情况\n",
    "        eb_res=(pred[-1]-bat_min)#电池可以放的电量\n",
    "        if(eb_res<0.01):#电池没电的情况\n",
    "            pg_import[d][i]=(abs(p_res))#买电，满足需求\n",
    "            pg_export[d][i]=(0)\n",
    "            pb_d[d][i]=(0)\n",
    "            pb_c[d][i]=(0)\n",
    "        else:#电池有电的情况\n",
    "            pb_d[d][i]=(min(pb_bar,min(abs(p_res)/eff_i,(eb_res*eff_c)/(dh))))#放到电池外面的电\n",
    "            pb_c[d][i]=(0)\n",
    "            pg_import[d][i]=((abs(p_res)-pb_d[d][i]*eff_i))#应该是买电，论文中的算法有错误\n",
    "            pg_export[d][i]=(0)\n",
    "    else:\n",
    "        pg_import[d][i]=(0.0)\n",
    "        pg_export[d][i]=(0.0)\n",
    "        pb_c[d][i]=(0.0)\n",
    "        pb_d[d][i]=(0.0)\n",
    "    pred.append(pred[-1]+(eff_c*pb_c[d][i]-pb_d[d][i]/eff_c))#此处没有乘以dh，因为单位为千瓦\n",
    "    #pred.append(pred[-1]+dh*(eff_c*pb_c[d][i]-pb_d[d][i]/eff_c))\n",
    "    return pg_import,pg_export,pb_c,pb_d,pred\n",
    "\n",
    "def update(predict,ggtemp,loadtemp,user,GG_array,Total_Load_array,d,i,pred,\n",
    "           pg_import,pg_export,pb_c,pb_d,bat_max,eff_i,eff_c,dh,theta):\n",
    "############电池单位为千瓦时，其他都是以千瓦为单位####\n",
    "    soc_before=pred[-1]\n",
    "    theta1=(predict-soc_before)\n",
    "    if(theta1>=0.0):#要充电\n",
    "        pb_c[d][i]=(theta1)/(dh*eff_c)\n",
    "        pb_d[d][i]=(0)\n",
    "        theta2=GG_array[d][i]*eff_i-Total_Load_array[d][i]-pb_c[d][i]*eff_c*eff_i#下一时刻实际发电量是否满足\n",
    "        \n",
    "        if(theta2>=0):#发电量够了,卖电\n",
    "            pg_import[d][i]=0\n",
    "            pg_export[d][i]=(theta2)#卖出多余的电\n",
    "        else:#thata3<0，剩余发电量不能满足负载，买电\n",
    "            pg_import[d][i]=(abs(theta2))\n",
    "            pg_export[d][i]=(0)\n",
    "    else:#要放电\n",
    "        pb_c[d][i]=(0)\n",
    "        pb_d[d][i]=abs(theta1*eff_c)/(dh)\n",
    "        theta2=GG_array[d][i]*eff_i-Total_Load_array[d][i]-pb_d[d][i]*eff_i/eff_c#下一时刻实际发电量是否满足\n",
    "        if(theta2>=0):#放的电能满足负载\n",
    "            pg_export[d][i]=(theta2)\n",
    "            pg_import[d][i]=[0]\n",
    "        else:\n",
    "            pg_import[d][i]=abs(theta2)\n",
    "            pg_export[d][i]=(0)\n",
    "    return pg_import,pg_export,pb_c,pb_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##滚动法求24小时的最佳SOC，选取最前一段作为SOC，这里默认充放电功率界限和效率一样\n",
    "def milp_oneip(theta,T_tou,T_fit,Total_Load_array,GG_array,bat_state,i,d,pb_bar,bat_max,efficiency_i,efficiency_c,dh,pg_bar):\n",
    "    expression=0\n",
    "    tfit=[]\n",
    "    model = Model()####对变量命名并且给出上下界\n",
    "    var_list = np.arange(0,48,1)\n",
    "    X1 = model.continuous_var_list(var_list,lb=0.0,ub=pg_bar,name='X1')#代表pg_import(pg+)，功率\n",
    "    X2 = model.continuous_var_list(var_list,lb=0.0,ub=pg_bar,name='X2')#代表pg_export(pg-)\n",
    "    Y1 = model.continuous_var_list(var_list,lb=0.0,ub=pb_bar,name='Y1')#代表充电功率（pb+）\n",
    "    Y2 = model.continuous_var_list(var_list,lb=0.0,ub=pb_bar,name='Y2')#代表放电功率（pb-）\n",
    "    dg=model.binary_var_list(var_list,name='dg')#决策变量电网电力流向（0：用户到电网）\n",
    "    sb=model.binary_var_list(var_list,name='sb')#决策变量电池充电状态（0：放电）\n",
    "    eb=model.continuous_var_list(var_list,lb=0,name='eb')#电池容量SOC\n",
    "    tou=[]\n",
    "    tou.extend(T_tou[i:])\n",
    "    tou.extend(T_tou[0:i])#输入分时电价\n",
    "    \n",
    "    for j in range(48):\n",
    "        #tfit.append(T_fit)\n",
    "        expression+=tou[j]*X1[j]*dh#X1为pg+,X2为pg-,Y1为pb+,Y2为pb-\n",
    "        expression-=T_fit*X2[j]*dh\n",
    "    #约束条件（2）\n",
    "\n",
    "        if(j+i<48):#i表示第几个时刻\n",
    "            model.add_constraint(X1[j]-X2[j]-efficiency_i*efficiency_c*Y1[j]+(efficiency_i/efficiency_c)*Y2[j]==\n",
    "                         Total_Load_array[d-7][j+i]-efficiency_i*(GG_array[d][j+i]+np.random.uniform(-theta*GG_array[d][j+i], theta*GG_array[d][j+i])))\n",
    "        else:\n",
    "            model.add_constraint(X1[j]-X2[j]-efficiency_i*efficiency_c*Y1[j]+(efficiency_i/efficiency_c)*Y2[j]==\n",
    "                         Total_Load_array[d+1-7][j+i-48]-efficiency_i*(GG_array[d+1][j+i-48]+np.random.uniform(-theta*GG_array[d][j+i-48], theta*GG_array[d][j+i-48])))\n",
    "\n",
    "    #约束条件（3）\n",
    "        bat_state.append(bat_state[-1]+dh*efficiency_c*Y1[j]-(dh/efficiency_c)*Y2[j])#约束条件（3）\n",
    "        eb[j]=bat_state[-1]\n",
    "        model.add_constraint(eb[j]<=bat_max)#约束条件（12）\n",
    "        model.add_constraint(eb[j]>=0)#约束条件（12）\n",
    "    #约束条件（4）\n",
    "        model.add_constraint(X1[j]-pg_bar*dg[j]<=0)\n",
    "    #约束条件（5）\n",
    "        model.add_constraint(X2[j]+pg_bar*dg[j]<=pg_bar)\n",
    "    #约束条件（6）\n",
    "        model.add_constraint(Y1[j]-pb_bar*sb[j]<=0)\n",
    "    #约束条件（7）\n",
    "        model.add_constraint(Y2[j]+pb_bar*sb[j]<=pb_bar)\n",
    "    model.minimize(expression)#目标函数    \n",
    "    sol = model.solve() #输出解\n",
    "    temp = sol.get_all_values()\n",
    "    return temp,bat_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##对用户进行364天的SOC计算\n",
    "def MILP2ip(Total_Load_array,GG_array,user,theta):\n",
    "    L={0: 4,1: 5,2: 4,3: 4,4: 5,5: 5,6: 3,7: 3,8: 5,9: 5,10: 5,11: 8,12: 10,13: 7,14: 5,\n",
    " 15: 5,16: 5,17: 4,18: 4,19: 10,20: 6,21: 5,22: 3,23: 4,24: 5,25: 6,26: 4,27: 9,28: 5,29: 10,\n",
    " 30: 6,31: 5,32: 4,33: 3,34: 4,35: 5,36: 8,37: 5,38: 3,39: 4,40: 5,41: 6,42: 5,43: 4,\n",
    " 44: 5,45: 4,46: 4,47: 5,48: 4,49: 6,50: 9,51: 7,52: 5,53: 4}\n",
    "    #注意这里29和30是作者剔除的，这里考虑进来了\n",
    "    days=364\n",
    "    efficiency_i=0.9\n",
    "    efficiency_c=0.95\n",
    "    dh=0.5\n",
    "    pg_bar=20\n",
    "    T_flat=0.235018\n",
    "    T_fit=0.09\n",
    "    T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]\n",
    "    if(L[user]==3 or L[user]==4):\n",
    "        init_state=6.5\n",
    "        pb_bar=4.2\n",
    "    elif(L[user]==5 or L[user]==6):\n",
    "        init_state=9.8\n",
    "        pb_bar=5\n",
    "    elif(L[user] in [7,8,9,10]):\n",
    "        init_state=14\n",
    "        pb_bar=5\n",
    "        \n",
    "    bat_max=init_state\n",
    "    #bat_state=[0.5*init_state]#要输出的电池状态，这是0时刻的初始状态\n",
    "    bat_state=[0]\n",
    "    pg_import=[[0 for i in range(48)] for _ in range(days)]\n",
    "    pg_export=[[0 for i in range(48)] for _ in range(days)]\n",
    "    pb_c=[[0 for i in range(48)] for _ in range(days)]\n",
    "    pb_d=[[0 for i in range(48)] for _ in range(days)]\n",
    "    soc=[]#电池状态用一维数组接收\n",
    "    #soc[0]=[0.5*bat_max]\n",
    "    soc.append(0)#0是初试的\n",
    "    \n",
    "    for d in np.arange(14,360,1): \n",
    "        for i in range(48):\n",
    "        #print(bat_state)\n",
    "            temp=[]\n",
    "            temp,before=milp_oneip(theta,T_tou,T_fit,Total_Load_array,GG_array,bat_state,i,d,pb_bar,bat_max,efficiency_i,efficiency_c,dh,pg_bar)\n",
    "        #print(temp[96])\n",
    "            soc.append(before+dh*efficiency_c*temp[96]-(dh/efficiency_c)*temp[144])#bat_state保存的是滚动域内48个时刻都要满足电池约束，所以一个遍历完后得\n",
    "        #重置，而SOC是要输出的值\n",
    "            bat_state=[]\n",
    "            bat_state.append(soc[-1])\n",
    "        #d=bat_state[-1]+0.455*a[0]-(0.5/0.91)*a[0]\n",
    "        #print(bat_state[-1])\n",
    "            pg_import[d][i]=(abs(temp[0]))\n",
    "            pg_export[d][i]=(abs(temp[48]))\n",
    "            pb_c[d][i]=(abs(temp[96]))\n",
    "            pb_d[d][i]=(abs(temp[144]))\n",
    "    return soc,pg_import,pg_export,pb_c,pb_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Total_Load_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHENXI~1\\AppData\\Local\\Temp/ipykernel_11504/376200671.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msoc_milp3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpg_import_milp3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpg_export_milp3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpb_c_milp3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpb_d_milp3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMILP2ip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTotal_Load_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGG_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoc_milp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Total_Load_array' is not defined"
     ]
    }
   ],
   "source": [
    "soc_milp3,pg_import_milp3,pg_export_milp3,pb_c_milp3,pb_d_milp3=MILP2ip(Total_Load_array,GG_array,user)\n",
    "len(soc_milp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2912.4660509340183"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_tou1=[]#PFA PP\n",
    "pg_import2,pg_export2,pb_c2,pb_d2=[],[],[],[]\n",
    "for i in np.arange(14,360,1):\n",
    "    T_tou1.extend(T_tou)\n",
    "    pg_import2.extend(pg_import[i])\n",
    "    pg_export2.extend(pg_export[i])\n",
    "\n",
    "cost,dh,T_fit=0,0.5,0.09\n",
    "for i in range(len(pg_import2)):\n",
    "    cost+=pg_import2[i]*T_tou1[i]*dh-pg_export2[i]*T_fit*dh\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1912.2763698200522"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load=[]#MILP PP\n",
    "GGG=[]\n",
    "T_tou1=[]\n",
    "pg_import3,pg_export3,pb_c3,pb_d3,soc3=[],[],[],[],[]\n",
    "for i in np.arange(14,360,1):\n",
    "    load.extend(Total_Load_array[i])\n",
    "    GGG.extend(GG_array[i])\n",
    "    T_tou1.extend(T_tou)\n",
    "    pg_import3.extend(pg_import_milp[i])\n",
    "    pg_export3.extend(pg_export_milp[i])\n",
    "    pb_c3.extend(pb_c_milp[i])\n",
    "    pb_d3.extend(pb_d_milp[i])\n",
    "cost,dh,T_fit=0,0.5,0.09\n",
    "for i in range(len(pg_import3)):\n",
    "    cost+=pg_import3[i]*T_tou1[i]*dh-pg_export3[i]*T_fit*dh\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2083.212213698412"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load=[]\n",
    "GGG=[]\n",
    "T_tou1=[]\n",
    "pg_import4,pg_export4,pb_c4,pb_d4,soc4=[],[],[],[],[]\n",
    "for i in np.arange(14,360,1):\n",
    "    T_tou1.extend(T_tou)\n",
    "    pg_import4.extend(pg_import_milp3[i])\n",
    "    pg_export4.extend(pg_export_milp3[i])\n",
    "cost,dh,T_fit=0,0.5,0.09\n",
    "for i in range(len(pg_import4)):\n",
    "    cost+=pg_import4[i]*T_tou1[i]*dh-pg_export4[i]*T_fit*dh\n",
    "cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
