{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.mp.model import Model  #导出库，只用这一个就够了\n",
    "import matplotlib.pyplot as plt#选取了用户47的365天的数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cplex\n",
    "from cplex.exceptions import CplexError\n",
    "import time\n",
    "import math\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "import xlrd\n",
    "import torch\n",
    "from torch import nn\n",
    "#from matplotlib.animation import FuncAnimation\n",
    "#import matplotlib.animation as animation\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_year(year,user):\n",
    "    #read file, for example\n",
    "    file_path = 'C:/Users/chenxihui/Desktop/code/project/'+str(year)+'.csv'\n",
    "    file = open(file_path)\n",
    "    data = []\n",
    "    for i in file.readlines():\n",
    "        data.append(i)\n",
    "    file.close()\n",
    "    new_data = []\n",
    "\n",
    "    for row in data:\n",
    "        tmp = row.strip('\\n')  #去掉每行最后的回车符\n",
    "        tmp = tmp.split(',')   #根据','来分割字符串，使之成为含有一个个数据的列表\n",
    "        new_data.append(tmp)   #new_data的每一行数据就是一个列表\n",
    "    select_data = []\n",
    "    position=[1,3,6,12,14,15,16,18,19,22,23,26,28,31,32,34,38,41,42,43,45,46,47]\n",
    "    #这是在cluster里分类产生的结果，是人数最多的类，以此为对象\n",
    "    users=['2','13','14','20','33','35','38','39','56','69','73','74','75'\n",
    "          ,'82','87','88','101','104','106','109','110','119','124','130'\n",
    "          ,'137','141','144','152','153','157','161','169','176','184','188'\n",
    "          ,'189','193','201','202','204','206','207','210','211','212','214'\n",
    "          ,'218','244','246','253','256','273','276','297']\n",
    "    \n",
    "    \"\"\"\n",
    "        user_chosen=[]\n",
    "    for item in position:\n",
    "        user_chosen.append(users[item])\n",
    "    \"\"\"\n",
    "        \n",
    "    length=len(new_data)\n",
    "    for i in range(length):\n",
    "        if(new_data[i][0]==users[user]):\n",
    "            select_data.append(new_data[i][3:])#[5:]\n",
    "            pv_size=float(new_data[i][1])\n",
    "    GC=[]\n",
    "    CL=[]\n",
    "    GG=[]\n",
    "    Length_select_data = len(select_data)\n",
    "    for i in range(Length_select_data):\n",
    "        if(select_data[i][0]=='GC'):\n",
    "            GC.append(select_data[i][2:])\n",
    "        elif(select_data[i][0]=='CL'):\n",
    "            CL.append(select_data[i][2:])\n",
    "        else:\n",
    "            GG.append(select_data[i][2:])\n",
    "            \n",
    "    Total_Load=[]\n",
    "    temp=[]\n",
    "    a=0.0\n",
    "    for i in range(Length_select_data):\n",
    "        if(select_data[i][0]=='GC' and select_data[i+1][0]=='CL'):\n",
    "            for j in range(len(select_data[i][2:])):\n",
    "                a=pd.to_numeric(select_data[i][j+2])+pd.to_numeric(select_data[i+1][j+2])\n",
    "                temp.append(a)\n",
    "            Total_Load.append(temp)\n",
    "        elif(select_data[i][0]=='GC' and select_data[i+1][0]!='CL'):\n",
    "            Total_Load.append(select_data[i][2:])\n",
    "        temp=[]\n",
    "        \n",
    "    GC_temp=np.array(GC)\n",
    "    GC_array=[]\n",
    "    GC_array = GC_temp.astype(np.float)\n",
    "\n",
    "    GG_temp=np.array(GG)\n",
    "    GG_array=[]\n",
    "    GG_array = GG_temp.astype(np.float)*2\n",
    "    \n",
    "    Total_Load_temp=np.array(Total_Load)\n",
    "    Total_Load_array=[]\n",
    "    Total_Load_array = Total_Load_temp.astype(np.float32)*2#功率\n",
    "    \n",
    "    return GG_array,Total_Load_array,pv_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def milp_one2(T_tou,T_fit,Total_Load_array,GG_array,bat_state,i,d,pb_bar,bat_max,efficiency_i,efficiency_c,dh,pg_bar):\n",
    "    expression=0\n",
    "    tfit=[]\n",
    "    model = Model()####对变量命名并且给出上下界\n",
    "    var_list = np.arange(0,48,1)\n",
    "    X1 = model.continuous_var_list(var_list,lb=0.0,ub=pg_bar,name='X1')#代表pg_import(pg+)，功率\n",
    "    X2 = model.continuous_var_list(var_list,lb=0.0,ub=pg_bar,name='X2')#代表pg_export(pg-)\n",
    "    Y1 = model.continuous_var_list(var_list,lb=0.0,ub=pb_bar,name='Y1')#代表充电功率（pb+）\n",
    "    Y2 = model.continuous_var_list(var_list,lb=0.0,ub=pb_bar,name='Y2')#代表放电功率（pb-）\n",
    "    dg=model.binary_var_list(var_list,name='dg')#决策变量电网电力流向（0：用户到电网）\n",
    "    sb=model.binary_var_list(var_list,name='sb')#决策变量电池充电状态（0：放电）\n",
    "    eb=model.continuous_var_list(var_list,lb=0,name='eb')#电池容量SOC\n",
    "    tou=[]\n",
    "    tou.extend(T_tou[i:])\n",
    "    tou.extend(T_tou[0:i])#输入分时电价\n",
    "    \n",
    "    for j in range(48):\n",
    "        #tfit.append(T_fit)\n",
    "        expression+=tou[j]*X1[j]*dh#X1为pg+,X2为pg-,Y1为pb+,Y2为pb-\n",
    "        expression-=T_fit*X2[j]*dh\n",
    "    #约束条件（2）\n",
    "        if(j+i<48):\n",
    "            model.add_constraint(X1[j]-X2[j]-efficiency_i*efficiency_c*Y1[j]+(efficiency_i/efficiency_c)*Y2[j]==\n",
    "                         Total_Load_array[d][j+i]-efficiency_i*GG_array[d][j+i])\n",
    "        else:\n",
    "            model.add_constraint(X1[j]-X2[j]-efficiency_i*efficiency_c*Y1[j]+(efficiency_i/efficiency_c)*Y2[j]==\n",
    "                         Total_Load_array[d+1][j+i-48]-efficiency_i*GG_array[d+1][j+i-48])\n",
    "        \n",
    "    #约束条件（3）\n",
    "        bat_state.append(bat_state[-1]+dh*efficiency_c*Y1[j]-(dh/efficiency_c)*Y2[j])#约束条件（3）\n",
    "        eb[j]=bat_state[-1]\n",
    "        model.add_constraint(eb[j]<=bat_max)#约束条件（12）\n",
    "        model.add_constraint(eb[j]>=0)#约束条件（12）\n",
    "    #约束条件（4）\n",
    "        model.add_constraint(X1[j]-pg_bar*dg[j]<=0)\n",
    "    #约束条件（5）\n",
    "        model.add_constraint(X2[j]+pg_bar*dg[j]<=pg_bar)\n",
    "    #约束条件（6）\n",
    "        model.add_constraint(Y1[j]-pb_bar*sb[j]<=0)\n",
    "    #约束条件（7）\n",
    "        model.add_constraint(Y2[j]+pb_bar*sb[j]<=pb_bar)\n",
    "    model.minimize(expression)#目标函数    \n",
    "    sol = model.solve() #输出解\n",
    "    temp = sol.get_all_values()\n",
    "    return temp,bat_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MILP_365(Total_Load_array,GG_array,user):\n",
    "    L={0: 4,1: 5,2: 4,3: 4,4: 5,5: 5,6: 3,7: 3,8: 5,9: 5,10: 5,11: 8,12: 10,13: 7,14: 5,\n",
    " 15: 5,16: 5,17: 4,18: 4,19: 10,20: 6,21: 5,22: 3,23: 4,24: 5,25: 6,26: 4,27: 9,28: 5,29: 9.99,\n",
    " 30: 3.2,31: 5,32: 4,33: 3,34: 4,35: 5,36: 8,37: 5,38: 3,39: 4,40: 5,41: 6,42: 5,43: 4,\n",
    " 44: 5,45: 4,46: 4,47: 5,48: 4,49: 6,50: 9,51: 7,52: 5,53: 4}\n",
    "    days=364\n",
    "    efficiency_i=0.9\n",
    "    efficiency_c=0.95\n",
    "    dh=0.5\n",
    "    pg_bar=20\n",
    "    T_flat=0.235018\n",
    "    T_fit=0.09\n",
    "    T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]\n",
    "    if(L[user]==3 or L[user]==4):\n",
    "        init_state=6.5\n",
    "        pb_bar=4.2\n",
    "    elif(L[user]==5 or L[user]==6):\n",
    "        init_state=9.8\n",
    "        pb_bar=5\n",
    "    elif(L[user] in [7,8,9,10]):\n",
    "        init_state=14\n",
    "        pb_bar=5\n",
    "    bat_max=init_state\n",
    "    bat_state=[0.5*init_state]#要输出的电池状态，这是0时刻的初始状态\n",
    "    pg_import=[[] for _ in range(days)]\n",
    "    pg_export=[[] for _ in range(days)]\n",
    "    pb_c=[[] for _ in range(days)]\n",
    "    pb_d=[[] for _ in range(days)]\n",
    "    soc=[[] for _ in range(days)]\n",
    "    soc[0]=[0.5*bat_max]\n",
    "    a=time.time()\n",
    "    for d in np.arange(0,days,1): \n",
    "        for i in range(48):\n",
    "        #print(bat_state)\n",
    "            temp=[]\n",
    "            temp,before=milp_one2(T_tou,T_fit,Total_Load_array,GG_array,bat_state,i,d,pb_bar,bat_max,efficiency_i,efficiency_c,dh,pg_bar)\n",
    "        #print(temp[96])\n",
    "            if(i==47 and d<days-1):\n",
    "                soc[d+1].append(abs(before+dh*efficiency_c*temp[96]-(dh/efficiency_c)*temp[144]))\n",
    "            elif(i<47):     \n",
    "                soc[d].append(abs(before+dh*efficiency_c*temp[96]-(dh/efficiency_c)*temp[144]))#bat_state保存的是滚动域内48个时刻都要满足电池约束，所以一个遍历完后得\n",
    "        #重置，而SOC是要输出的值\n",
    "            bat_state=[]\n",
    "            bat_state.append(soc[d][-1])\n",
    "        #d=bat_state[-1]+0.455*a[0]-(0.5/0.91)*a[0]\n",
    "        #print(bat_state[-1])\n",
    "            pg_import[d].append(abs(temp[0]))\n",
    "            pg_export[d].append(abs(temp[48]))\n",
    "            pb_c[d].append(abs(temp[96]))\n",
    "            pb_d[d].append(abs(temp[144]))\n",
    "    return soc,pg_import,pg_export,pb_c,pb_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data,path):\n",
    "    wb = Workbook()\n",
    "    ws = wb.active # 激活 worksheet\n",
    "    [h, l] = np.array(data).shape  # h为行数，l为列数\n",
    "    for i in range(h):\n",
    "        row = []\n",
    "        for j in range(l):\n",
    "            row.append(format(data[i][j],'.4f'))\n",
    "        ws.append(row)\n",
    "    wb.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(road):\n",
    "    workbook=openpyxl.load_workbook(\"C:/Users/chenxihui/Desktop/code/project/processed_data/\"+road+\".xlsx\")\n",
    "    shenames=workbook.sheetnames\n",
    "    worksheet=workbook.worksheets[0]\n",
    "    name=worksheet.title \n",
    "    rows=worksheet.max_row\n",
    "    columns=worksheet.max_column\n",
    "    data_read=[[] for i in range(rows)]\n",
    "    i=0\n",
    "    for row in worksheet.rows:\n",
    "        for cell in row:\n",
    "            data_read[i].append(cell.value)\n",
    "        i=i+1\n",
    "    data_temp=np.array(data_read)\n",
    "    data_array=[]\n",
    "    data_array=data_temp.astype(np.float)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples(T_tou,soc_y,Total_Load_array,GG_array):\n",
    "    #此版本为362天的样本数据点集合,从第一天开始算，但是第一天里都是空集合\n",
    "    T_tou_temp=[]\n",
    "    for i in range(3):\n",
    "        T_tou_temp.extend(T_tou)\n",
    "    days=365    \n",
    "    data_365=[[[] for _ in range(48)] for _ in range(days)]\n",
    "    for d in range(days):\n",
    "        for i in range(48):\n",
    "            data_temp=[]\n",
    "            GG_temp=[]\n",
    "            soc_temp=[]#前48个SOC（包含当前时刻）\n",
    "            ToU_temp=[]\n",
    "            load_temp=[]\n",
    "            if(d<363 and d>0):\n",
    "                if(i==0):\n",
    "                    soc_temp=np.hstack((soc_y[d-1][i+1:],soc_y[d][0:i+1]))\n",
    "                    ToU_temp=np.hstack((T_tou[i:],T_tou))\n",
    "                    load_temp=np.hstack((Total_Load_array[d][i:],Total_Load_array[d+1]))\n",
    "                    GG_temp=np.hstack((GG_array[d][i:],GG_array[d+1]))\n",
    "                elif(i==47):\n",
    "                    soc_temp=soc_y[d]\n",
    "                    ToU_temp=np.hstack((T_tou,T_tou))\n",
    "                #print(\"ToU_temp:\",ToU_temp)\n",
    "                    load_temp=np.hstack((Total_Load_array[d],Total_Load_array[d+1]))\n",
    "                    GG_temp=np.hstack((GG_array[d],GG_array[d+1]))\n",
    "                else:\n",
    "                    soc_temp=np.hstack((soc_y[d-1][i+1:],soc_y[d][0:i+1]))\n",
    "                    ToU_temp=np.hstack((T_tou[i:],T_tou,T_tou[:i]))\n",
    "                    GG_temp=np.hstack((GG_array[d][i:],GG_array[d+1],GG_array[d+2][:i]))\n",
    "                    load_temp=np.hstack((Total_Load_array[d][i:],Total_Load_array[d+1],Total_Load_array[d+2][:i]))\n",
    "            data_temp=soc_temp\n",
    "            data_temp=np.hstack((data_temp,ToU_temp))\n",
    "            data_temp=np.hstack((data_temp,list(map(float, GG_temp))))\n",
    "            data_temp=np.hstack((data_temp,load_temp))\n",
    "            data_365[d][i]=data_temp\n",
    "    return data_365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train(year,user):\n",
    "    T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]\n",
    "    \n",
    "    GG_array,Total_Load_array,pv_size=Read_year(year,user)\n",
    "    soc_y=read_data(\"soc-\"+str(year)+\"-\"+str(user)+\"-\")\n",
    "    data_365=samples(T_tou,soc_y,Total_Load_array,GG_array)\n",
    "    a=np.array(data_365[1:302]).transpose((1,0,2))\n",
    "    soc_label=[[]for i in range(360)]\n",
    "    for i in range(360):\n",
    "        for j in np.arange(1,48):\n",
    "            soc_label[i].append(soc_y[i+1][j])\n",
    "        soc_label[i].append(soc_y[i+2][0])\n",
    "    return a,soc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 此为300天-340天数据作为同一用户的测试集\n",
    "def RNN_test(year,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func):    \n",
    "    print(\"Testing...load model...\")\n",
    "    filepath = \"./model/rnn\"+str(year)+\"-\"+str(user)+\".model\"\n",
    "    checkpoint = torch.load(filepath)\n",
    "    rnn.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    '''\n",
    "    print('Model.state_dict:')\n",
    "    for param_tensor in rnn.state_dict():\n",
    "        #打印 key value字典\n",
    "        print(param_tensor,'\\t',rnn.state_dict()[param_tensor].size())\n",
    " \n",
    "    print('Optimizer,s state_dict:')\n",
    "    for var_name in optimizer.state_dict():\n",
    "        print(var_name,'\\t',optimizer.state_dict()[var_name])\n",
    "    '''\n",
    "    rnn.eval()\n",
    "    \n",
    "    test,soc_label=generate_test(year,user)\n",
    "    testloss=0\n",
    "    with torch.no_grad():\n",
    "        for step in range(40):\n",
    "            test_x=torch.from_numpy(np.array(test[:,step,np.newaxis])).float().to(device)\n",
    "            test_y = torch.from_numpy(np.array(soc_label[step+301])[:,np.newaxis,np.newaxis]).float().to(device)\n",
    "            predict, h_state = rnn(test_x,h_state)\n",
    "            loss_test = loss_func(predict, test_y)\n",
    "            testloss+=loss_test\n",
    "    print(str(user)+\"testloss：\"+str(testloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test(year,user):\n",
    "    T_tou=[0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,0.2134,\n",
    "       0.38588,0.38588, 0.38588,0.38588, \n",
    "      0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,0.37147,\n",
    "      0.38588,0.38588,0.38588,0.38588,0.38588,0.38588,\n",
    "      0.37147,0.37147,0.37147,0.37147,\n",
    "      0.2134,0.2134,0.2134,0.2134]\n",
    "    GG_array,Total_Load_array,pv_size=Read_year(year,user)\n",
    "    soc_y=read_data(\"soc-\"+str(year)+\"-\"+str(user)+\"-\")\n",
    "    data_365=samples(T_tou,soc_y,Total_Load_array,GG_array)\n",
    "    \n",
    "    test=np.array(data_365[302:342]).transpose((1,0,2))#测试集从第302天开始\n",
    "    \n",
    "    soc_label=[[]for i in range(360)]\n",
    "    for i in range(360):\n",
    "        for j in np.arange(1,48):\n",
    "            soc_label[i].append(soc_y[i+1][j])\n",
    "        soc_label[i].append(soc_y[i+2][0])\n",
    "    return test,soc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_train(year,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func):\n",
    "    a,soc_label = generate_train(year,user)\n",
    "    train_loss=[]\n",
    "    lr_list = []\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50,100,150,200,250,300], gamma=0.6)\n",
    "    for step in range(N_EPOCHS):\n",
    "        error=0.0\n",
    "        for batch_num in range(batch_nums):#此处分成了43个batch \n",
    "            x=torch.from_numpy(np.array(a[:,batch_num,np.newaxis])).float().to(device)\n",
    "            y=torch.from_numpy(np.array(soc_label[batch_num])[:,np.newaxis,np.newaxis]).float().to(device)\n",
    "            prediction, h_state = rnn(x, h_state)  # RNN输出（预测结果，隐藏状态）\n",
    "            h_state = h_state.detach()  # 这一行很重要，将每一次输出的中间状态传递下去(不带梯度)，将h_state分离出来，同时不影响后向计算\n",
    "            loss = loss_func(prediction, y)\n",
    "            error += loss\n",
    "            optimizer.zero_grad()#清零，模型的参数梯度设成0\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # 学习率更新\n",
    "            lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "            #torch.save(rnn.state_dict(), 'C:/Users/chenxihui/Desktop/code/project/rnn.pt')\n",
    "        error /= batch_nums\n",
    "        train_loss.append(error)\n",
    "    print(str(user)+\"  train Loss = \" + str(error))\n",
    "    if not os.path.exists(\"./model/\"):\n",
    "        os.makedirs(\"./model/\")\n",
    "    filepath = \"./model/rnn\"+str(year)+\"-\"+str(user)+\".model\"\n",
    "    torch.save({\"model_state_dict\" : rnn.state_dict(),\n",
    "            \"optimizer_state_dict\" : optimizer.state_dict()},\n",
    "            filepath)   \n",
    "    #print(\"Model has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ###超参数设置\n",
    "    year=2012\n",
    "    TIME_STEP = 48  # RNN时间步长\n",
    "    INPUT_SIZE = 336  # RNN输入尺寸\n",
    "    INIT_LR = 0.01  # 初始学习率\n",
    "    N_EPOCHS = 300  # 训练回数\n",
    "    Batch_size=1\n",
    "    batch_nums=301\n",
    "    train_loss,test_loss=[],[]\n",
    "    ### RNN建立\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    class RNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(RNN, self).__init__()\n",
    "            self.rnn = nn.RNN(\n",
    "                input_size=INPUT_SIZE,\n",
    "                hidden_size=20,  # RNN隐藏神经元个数20\n",
    "                num_layers=1,  # RNN隐藏层个数\n",
    "            )\n",
    "            self.out = nn.Linear(20, 1).to(device)#全连接层\n",
    "\n",
    "        def forward(self, x, h):\n",
    "            out, h = self.rnn(x, h)\n",
    "            prediction = self.out(out)\n",
    "            return prediction, h\n",
    "        \n",
    "    rnn = RNN()\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr=INIT_LR)\n",
    "    loss_func = nn.MSELoss()\n",
    "    h_state = None \n",
    "    \n",
    "    ###step 1：得到分类结果，给出属于同一类的用户标号\n",
    "    position=[1,3,6,12,14,15,16,18,19,22,23,26,28,31,32,34,38,41,42,43,45,46,47]\n",
    "    scores=[]\n",
    "    ###step 2：处理该类中MILP、SOC，为了节约时间，将他们先处理保存，之后读取即可\n",
    "    #for user in position:\n",
    "        #GG_array,Total_Load_array,pv_size=Read_year(year,user)\n",
    "        #soc,pg_import,pg_export,pb_c,pb_d=MILP_365(Total_Load_array,GG_array,user)\n",
    "    ###step 3：对每个用户训练一个模型\n",
    "    for user in position:\n",
    "        #RNN_train(2012,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func)\n",
    "        RNN_test(2012,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func)\n",
    "    ###step 4：对每个用户训练出的模型进行测试（在其他用户身上）\n",
    "        testloss=model_test(year,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func)\n",
    "        scores.append(testloss)\n",
    "    ###step 5:选出类的特征模型\n",
    "    minscore=20\n",
    "    for i in range(len(scores)):\n",
    "        if(minscore>scores[i]):\n",
    "            minscore=scores[i]\n",
    "    for i in range(len(scores)):\n",
    "        if(minscore==scores[i]):\n",
    "            print(position[i])#得到该类中的特征模型的用户编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...load model...\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "A load persistent id instruction was encountered,\nbut no persistent_load function was specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4d5b83bddd69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m#RNN_train(2012,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mRNN_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_nums\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;31m###step 4：对每个用户训练出的模型进行测试（在其他用户身上）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mtestloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_nums\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-bac64bd80042>\u001b[0m in \u001b[0;36mRNN_test\u001b[1;34m(year, user, rnn, optimizer, N_EPOCHS, batch_nums, device, h_state, loss_func)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing...load model...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./model/rnn\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".model\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_state_dict\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"optimizer_state_dict\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\chen\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\chen\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m     \u001b[0mmagic_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: A load persistent id instruction was encountered,\nbut no persistent_load function was specified."
     ]
    }
   ],
   "source": [
    "###超参数设置\n",
    "year=2010\n",
    "TIME_STEP = 48  # RNN时间步长\n",
    "INPUT_SIZE = 336  # RNN输入尺寸\n",
    "INIT_LR = 0.01  # 初始学习率\n",
    "N_EPOCHS = 300  # 训练回数\n",
    "Batch_size=1\n",
    "batch_nums=301\n",
    "train_loss,test_loss=[],[]\n",
    "    ### RNN建立\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "                input_size=INPUT_SIZE,\n",
    "                hidden_size=20,  # RNN隐藏神经元个数20\n",
    "                num_layers=1,  # RNN隐藏层个数\n",
    "            )\n",
    "        self.out = nn.Linear(20, 1).to(device)#全连接层\n",
    "\n",
    "    def forward(self, x, h):\n",
    "            out, h = self.rnn(x, h)\n",
    "            prediction = self.out(out)\n",
    "            return prediction, h\n",
    "        \n",
    "rnn = RNN()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=INIT_LR)\n",
    "loss_func = nn.MSELoss()\n",
    "h_state = None \n",
    "    \n",
    "    ###step 1：得到分类结果，给出属于同一类的用户标号\n",
    "position=[12,13,21]\n",
    "scores=[]\n",
    "    ###step 2：处理该类中MILP、SOC，为了节约时间，将他们先处理保存，之后读取即可\n",
    "#for user in position:\n",
    "    #GG_array,Total_Load_array,pv_size=Read_year(year,user)\n",
    "    #soc,pg_import,pg_export,pb_c,pb_d=MILP_365(Total_Load_array,GG_array,user)\n",
    "    ###step 3：对每个用户训练一个模型\n",
    "for user in position:\n",
    "    #RNN_train(2012,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func)\n",
    "    RNN_test(year,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func)\n",
    "    ###step 4：对每个用户训练出的模型进行测试（在其他用户身上）\n",
    "    testloss=model_test(year,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func)\n",
    "    print(str(user)+\":\"+str(testloss))\n",
    "    scores.append(testloss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-fa8cef49474b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###step 4：对每个用户训练出的模型进行测试（在其他用户身上）\n",
    "def model_test(year,user,rnn,optimizer,N_EPOCHS,batch_nums,device,h_state,loss_func):    \n",
    "    position=[1,3,6,12,14,15,16,18,19,22,23,26,28,31,32,34,38,41,42,43,45,46,47]\n",
    "    print(\"Testing...load model...\")\n",
    "    filepath = \"./model/rnn\"+str(year)+\"-\"+str(user)+\".model\"\n",
    "    checkpoint = torch.load(filepath)\n",
    "    rnn.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "    rnn.eval()\n",
    "    testloss=0\n",
    "    for num in position:\n",
    "        test,soc_label=generate_test(2012,num)\n",
    "        with torch.no_grad():\n",
    "            for step in range(40):\n",
    "                test_x=torch.from_numpy(np.array(test[:,step,np.newaxis])).float().to(device)\n",
    "                test_y = torch.from_numpy(np.array(soc_label[step+301])[:,np.newaxis,np.newaxis]).float().to(device)\n",
    "                predict, h_state = rnn(test_x,h_state)\n",
    "                loss_test = loss_func(predict, test_y)\n",
    "                testloss+=loss_test\n",
    "    testloss=testloss/(40*23)\n",
    "    print(\"Test has been done! The LOSS is: \"+str(testloss))\n",
    "    return testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...load model...\n",
      "Test has been done in! The LOSS is: tensor(1.00000e-03 *\n",
      "       1.4796)\n"
     ]
    }
   ],
   "source": [
    "model_test(2012,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f7cba7e479cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mGG_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTotal_Load_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpv_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRead_year\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msoc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpg_import\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpg_export\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpb_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpb_d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMILP_365\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTotal_Load_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGG_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"C:/Users/chenxihui/Desktop/code/project/processed_data/soc-\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"has been done!!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-15312795f703>\u001b[0m in \u001b[0;36mMILP_365\u001b[1;34m(Total_Load_array, GG_array, user)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#print(bat_state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mtemp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbefore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmilp_one2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_tou\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT_fit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTotal_Load_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGG_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbat_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpb_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbat_max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mefficiency_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mefficiency_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpg_bar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;31m#print(temp[96])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m47\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-81e9da3780c8>\u001b[0m in \u001b[0;36mmilp_one2\u001b[1;34m(T_tou, T_fit, Total_Load_array, GG_array, bat_state, i, d, pb_bar, bat_max, efficiency_i, efficiency_c, dh, pg_bar)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpb_bar\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m#约束条件（7）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpb_bar\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[0mpb_bar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#目标函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0msol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#输出解\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\chen\\lib\\site-packages\\docplex\\mp\\operand.py\u001b[0m in \u001b[0;36m__le__\u001b[1;34m(self, rhs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__le__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_xconstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomparaison_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mComparisonType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\chen\\lib\\site-packages\\docplex\\mp\\model.py\u001b[0m in \u001b[0;36m_new_xconstraint\u001b[1;34m(self, lhs, rhs, comparaison_type)\u001b[0m\n\u001b[0;32m   3891\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qfactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_qconstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomparaison_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3892\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3893\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lfactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_binary_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomparaison_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3895\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_constraints_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\chen\\lib\\site-packages\\docplex\\mp\\mfactory.py\u001b[0m in \u001b[0;36m_new_binary_constraint\u001b[1;34m(self, lhs, sense, rhs, name)\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;31m# noinspection PyPep8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mleft_expr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_linear_operand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"LinearConstraint. expects linear expressions, {0} was passed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m         \u001b[0mright_expr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_linear_operand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"LinearConstraint. expects linear expressions, {0} was passed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypecheck_two_in_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_expr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_expr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"new_binary_constraint\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[0mct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearConstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_expr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_expr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\chen\\lib\\site-packages\\docplex\\mp\\mfactory.py\u001b[0m in \u001b[0;36m_to_linear_operand\u001b[1;34m(self, e, force_clone, msg)\u001b[0m\n\u001b[0;32m    575\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe_number\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\chen\\lib\\site-packages\\docplex\\mp\\mfactory.py\u001b[0m in \u001b[0;36mconstant_expr\u001b[1;34m(self, cst, safe_number)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_zero_expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_constant_expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe_number\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msafe_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlinear_expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\chen\\lib\\site-packages\\docplex\\mp\\mfactory.py\u001b[0m in \u001b[0;36m_new_constant_expr\u001b[1;34m(self, cst, safe_number)\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0mself_number_validation_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_validation_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself_number_validation_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                 \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_number_validation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mConstantExpr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\chen\\lib\\site-packages\\docplex\\mp\\tck.py\u001b[0m in \u001b[0;36mstatic_validate_num1\u001b[1;34m(e, checked_num, infinity)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstatic_validate_num1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchecked_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfinity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e+20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# checks for number and truncates to 1e=20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchecked_num\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mdocplex_fatal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting number, got: {0!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0minfinity\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0minfinity\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\chenxihui\\Anaconda3\\envs\\chen\\lib\\site-packages\\docplex\\mp\\utils.py\u001b[0m in \u001b[0;36mis_number\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[0mtype_of_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtype_of_s\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m__all_python_num_types\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnumpy_is_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_of_s\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_is_numpy_ndslot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "year=2012\n",
    "    ###step 1：得到分类结果，给出属于同一类的用户标号\n",
    "position=[1,3,6,12,14,15,16,18,19,22,23,26,28,31,32,34,38,41,42,43,45,46,47]\n",
    "    ###step 2：处理该类中MILP、SOC，为了节约时间，将他们先处理保存，之后读取即可\n",
    "for user in position:\n",
    "    GG_array,Total_Load_array,pv_size=Read_year(year,user)\n",
    "    soc,pg_import,pg_export,pb_c,pb_d=MILP_365(Total_Load_array,GG_array,user)\n",
    "    save(soc,\"C:/Users/chenxihui/Desktop/code/project/processed_data/soc-\"+str(year)+\"-\"+str(user)+\"-\"+\".xlsx\")\n",
    "    print(str(user)+\"has been done!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2012\n",
    "\n",
    "users=['2','13','14','20','33','35','38','39','56','69','73','74','75'\n",
    "          ,'82','87','88','101','104','106','109','110','119','124','130'\n",
    "          ,'137','141','144','152','153','157','161','169','176','184','188'\n",
    "          ,'189','193','201','202','204','206','207','210','211','212','214'\n",
    "          ,'218','244','246','253','256','273','276','297']\n",
    "pv=[]\n",
    "for i in range(54): \n",
    "    GG_array,Total_Load_array,pv_size=Read_year(year,i)\n",
    "    pv.append(pv_size)\n",
    "\n",
    "a={}\n",
    "for i in range(54):\n",
    "    a[i]= pv[i]\n",
    "L=a\n",
    "#L=list(a.items())\n",
    "#L.sort(key=lambda x:x[1],reverse=False)\n",
    "for i in range(54):\n",
    "    if(i in [6,7,33,38,22]):\n",
    "        L[i]=3\n",
    "    elif(i in [2,17 ,34 ,18,23,26,43,53 ,45,46,48,3,39,0,32]):\n",
    "        L[i]=4\n",
    "    elif(i in [37,15 ,24 ,40 ,42,10,14 ,47 ,52,9 ,16 ,31,35 ,4 ,5,8 ,21,28,44,1]):\n",
    "        L[i]=5\n",
    "    elif(i in [41,20,49,25]):\n",
    "        L[i]=6\n",
    "    elif(i in [51,13] ):\n",
    "        L[i]=7\n",
    "    elif(i in [36,11] ):\n",
    "        L[i]=8\n",
    "    elif(i in [27,50] ):\n",
    "        L[i]=9\n",
    "    elif(i in [19,12]):\n",
    "        L[i]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "L={0: 4,1: 5,2: 4,3: 4,4: 5,5: 5,6: 3,7: 3,8: 5,9: 5,10: 5,11: 8,12: 10,13: 7,14: 5,\n",
    " 15: 5,16: 5,17: 4,18: 4,19: 10,20: 6,21: 5,22: 3,23: 4,24: 5,25: 6,26: 4,27: 9,28: 5,29: 9.99,\n",
    " 30: 3.2,31: 5,32: 4,33: 3,34: 4,35: 5,36: 8,37: 5,38: 3,39: 4,40: 5,41: 6,42: 5,43: 4,\n",
    " 44: 5,45: 4,46: 4,47: 5,48: 4,49: 6,50: 9,51: 7,52: 5,53: 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.22\n",
      "1.57\n",
      "1.05\n",
      "8.0\n",
      "2.0\n",
      "1.8\n",
      "2.04\n",
      "1.5\n",
      "6.2\n",
      "1.2\n",
      "1.5\n",
      "1.5\n",
      "2.1\n",
      "2.04\n",
      "1.75\n",
      "1.48\n",
      "1.05\n",
      "2.7\n",
      "1.94\n",
      "1.5\n",
      "1.53\n",
      "1.53\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "#因为在MILP时，PVsize大小啥的都是变的\n",
    "year=2012\n",
    "\n",
    "users=['2','13','14','20','33','35','38','39','56','69','73','74','75'\n",
    "          ,'82','87','88','101','104','106','109','110','119','124','130'\n",
    "          ,'137','141','144','152','153','157','161','169','176','184','188'\n",
    "          ,'189','193','201','202','204','206','207','210','211','212','214'\n",
    "          ,'218','244','246','253','256','273','276','297']\n",
    "position=[1,3,6,12,14,15,16,18,19,22,23,26,28,31,32,34,38,41,42,43,45,46,47]\n",
    "pv=[]\n",
    "for item in position: \n",
    "    GG_array,Total_Load_array,pv_size=Read_year(year,item)\n",
    "    #soc,pg_import,pg_export,pb_c,pb_d=MILP_365(pv_size,Total_Load_array,GG_array)\n",
    "    #save(soc,\"C:/Users/chenxihui/Desktop/code/project/processed_data/soc\"+str(year)+str(i)+\".xlsx\")\n",
    "    #print(str(i)+\"has been done!\")\n",
    "    #print(pv_size)\n",
    "    pv.append(pv_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chen",
   "language": "python",
   "name": "chen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
